dataflow_graph {
  kernels {
    name: "Iteration_1"
    id: 1
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 131072
      K: 131072
      N: 2048
      input_tensor_1_size: 2147483600.0
      output_tensor_size: 2147483600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2147483600.0
      shard_outer_M: 8192
      shard_K: 8192
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2147483600.0
    }
  }
  kernels {
    name: "Iteration_2"
    id: 2
    topological_number: 1
    config: 1
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 129024
      K: 129024
      N: 2048
      input_tensor_1_size: 2113929200.0
      output_tensor_size: 2113929200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2113929200.0
      shard_outer_M: 8064
      shard_K: 8064
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2113929200.0
    }
  }
  kernels {
    name: "Iteration_3"
    id: 3
    topological_number: 2
    config: 2
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 126976
      K: 126976
      N: 2048
      input_tensor_1_size: 2080374800.0
      output_tensor_size: 2080374800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2080374800.0
      shard_outer_M: 7936
      shard_K: 7936
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2080374800.0
    }
  }
  kernels {
    name: "Iteration_4"
    id: 4
    topological_number: 3
    config: 3
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 124928
      K: 124928
      N: 2048
      input_tensor_1_size: 2046820400.0
      output_tensor_size: 2046820400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2046820400.0
      shard_outer_M: 7808
      shard_K: 7808
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2046820400.0
    }
  }
  kernels {
    name: "Iteration_5"
    id: 5
    topological_number: 4
    config: 4
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 122880
      K: 122880
      N: 2048
      input_tensor_1_size: 2013265900.0
      output_tensor_size: 2013265900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2013265900.0
      shard_outer_M: 7680
      shard_K: 7680
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2013265900.0
    }
  }
  kernels {
    name: "Iteration_6"
    id: 6
    topological_number: 5
    config: 5
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 120832
      K: 120832
      N: 2048
      input_tensor_1_size: 1979711500.0
      output_tensor_size: 1979711500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1979711500.0
      shard_outer_M: 7552
      shard_K: 7552
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1979711500.0
    }
  }
  kernels {
    name: "Iteration_7"
    id: 7
    topological_number: 6
    config: 6
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 118784
      K: 118784
      N: 2048
      input_tensor_1_size: 1946157000.0
      output_tensor_size: 1946157000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1946157000.0
      shard_outer_M: 7424
      shard_K: 7424
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1946157000.0
    }
  }
  kernels {
    name: "Iteration_8"
    id: 8
    topological_number: 7
    config: 7
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 116736
      K: 116736
      N: 2048
      input_tensor_1_size: 1912602600.0
      output_tensor_size: 1912602600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1912602600.0
      shard_outer_M: 7296
      shard_K: 7296
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1912602600.0
    }
  }
  kernels {
    name: "Iteration_9"
    id: 9
    topological_number: 8
    config: 8
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 114688
      K: 114688
      N: 2048
      input_tensor_1_size: 1879048200.0
      output_tensor_size: 1879048200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1879048200.0
      shard_outer_M: 7168
      shard_K: 7168
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1879048200.0
    }
  }
  kernels {
    name: "Iteration_10"
    id: 10
    topological_number: 9
    config: 9
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 112640
      K: 112640
      N: 2048
      input_tensor_1_size: 1845493800.0
      output_tensor_size: 1845493800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1845493800.0
      shard_outer_M: 7040
      shard_K: 7040
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1845493800.0
    }
  }
  kernels {
    name: "Iteration_11"
    id: 11
    topological_number: 10
    config: 10
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 110592
      K: 110592
      N: 2048
      input_tensor_1_size: 1811939300.0
      output_tensor_size: 1811939300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1811939300.0
      shard_outer_M: 6912
      shard_K: 6912
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1811939300.0
    }
  }
  kernels {
    name: "Iteration_12"
    id: 12
    topological_number: 11
    config: 11
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 108544
      K: 108544
      N: 2048
      input_tensor_1_size: 1778384900.0
      output_tensor_size: 1778384900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1778384900.0
      shard_outer_M: 6784
      shard_K: 6784
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1778384900.0
    }
  }
  kernels {
    name: "Iteration_13"
    id: 13
    topological_number: 12
    config: 12
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 106496
      K: 106496
      N: 2048
      input_tensor_1_size: 1744830500.0
      output_tensor_size: 1744830500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1744830500.0
      shard_outer_M: 6656
      shard_K: 6656
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1744830500.0
    }
  }
  kernels {
    name: "Iteration_14"
    id: 14
    topological_number: 13
    config: 13
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 104448
      K: 104448
      N: 2048
      input_tensor_1_size: 1711276000.0
      output_tensor_size: 1711276000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1711276000.0
      shard_outer_M: 6528
      shard_K: 6528
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1711276000.0
    }
  }
  kernels {
    name: "Iteration_15"
    id: 15
    topological_number: 14
    config: 14
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 102400
      K: 102400
      N: 2048
      input_tensor_1_size: 1677721600.0
      output_tensor_size: 1677721600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1677721600.0
      shard_outer_M: 6400
      shard_K: 6400
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1677721600.0
    }
  }
  kernels {
    name: "Iteration_16"
    id: 16
    topological_number: 15
    config: 15
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 100352
      K: 100352
      N: 2048
      input_tensor_1_size: 1644167200.0
      output_tensor_size: 1644167200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1644167200.0
      shard_outer_M: 6272
      shard_K: 6272
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1644167200.0
    }
  }
  kernels {
    name: "Iteration_17"
    id: 17
    topological_number: 16
    config: 16
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 98304
      K: 98304
      N: 2048
      input_tensor_1_size: 1610612700.0
      output_tensor_size: 1610612700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1610612700.0
      shard_outer_M: 6144
      shard_K: 6144
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1610612700.0
    }
  }
  kernels {
    name: "Iteration_18"
    id: 18
    topological_number: 17
    config: 17
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 96256
      K: 96256
      N: 2048
      input_tensor_1_size: 1577058300.0
      output_tensor_size: 1577058300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1577058300.0
      shard_outer_M: 6016
      shard_K: 6016
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1577058300.0
    }
  }
  kernels {
    name: "Iteration_19"
    id: 19
    topological_number: 18
    config: 18
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 94208
      K: 94208
      N: 2048
      input_tensor_1_size: 1543503900.0
      output_tensor_size: 1543503900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1543503900.0
      shard_outer_M: 5888
      shard_K: 5888
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1543503900.0
    }
  }
  kernels {
    name: "Iteration_20"
    id: 20
    topological_number: 19
    config: 19
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 92160
      K: 92160
      N: 2048
      input_tensor_1_size: 1509949400.0
      output_tensor_size: 1509949400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1509949400.0
      shard_outer_M: 5760
      shard_K: 5760
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1509949400.0
    }
  }
  kernels {
    name: "Iteration_21"
    id: 21
    topological_number: 20
    config: 20
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 90112
      K: 90112
      N: 2048
      input_tensor_1_size: 1476395000.0
      output_tensor_size: 1476395000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1476395000.0
      shard_outer_M: 5632
      shard_K: 5632
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1476395000.0
    }
  }
  kernels {
    name: "Iteration_22"
    id: 22
    topological_number: 21
    config: 21
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 88064
      K: 88064
      N: 2048
      input_tensor_1_size: 1442840600.0
      output_tensor_size: 1442840600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1442840600.0
      shard_outer_M: 5504
      shard_K: 5504
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1442840600.0
    }
  }
  kernels {
    name: "Iteration_23"
    id: 23
    topological_number: 22
    config: 22
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 86016
      K: 86016
      N: 2048
      input_tensor_1_size: 1409286100.0
      output_tensor_size: 1409286100.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1409286100.0
      shard_outer_M: 5376
      shard_K: 5376
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1409286100.0
    }
  }
  kernels {
    name: "Iteration_24"
    id: 24
    topological_number: 23
    config: 23
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 83968
      K: 83968
      N: 2048
      input_tensor_1_size: 1375731700.0
      output_tensor_size: 1375731700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1375731700.0
      shard_outer_M: 5248
      shard_K: 5248
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1375731700.0
    }
  }
  kernels {
    name: "Iteration_25"
    id: 25
    topological_number: 24
    config: 24
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 81920
      K: 81920
      N: 2048
      input_tensor_1_size: 1342177300.0
      output_tensor_size: 1342177300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1342177300.0
      shard_outer_M: 5120
      shard_K: 5120
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1342177300.0
    }
  }
  kernels {
    name: "Iteration_26"
    id: 26
    topological_number: 25
    config: 25
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 79872
      K: 79872
      N: 2048
      input_tensor_1_size: 1308622800.0
      output_tensor_size: 1308622800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1308622800.0
      shard_outer_M: 4992
      shard_K: 4992
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1308622800.0
    }
  }
  kernels {
    name: "Iteration_27"
    id: 27
    topological_number: 26
    config: 26
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 77824
      K: 77824
      N: 2048
      input_tensor_1_size: 1275068400.0
      output_tensor_size: 1275068400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1275068400.0
      shard_outer_M: 4864
      shard_K: 4864
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1275068400.0
    }
  }
  kernels {
    name: "Iteration_28"
    id: 28
    topological_number: 27
    config: 27
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 75776
      K: 75776
      N: 2048
      input_tensor_1_size: 1241514000.0
      output_tensor_size: 1241514000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1241514000.0
      shard_outer_M: 4736
      shard_K: 4736
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1241514000.0
    }
  }
  kernels {
    name: "Iteration_29"
    id: 29
    topological_number: 28
    config: 28
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 73728
      K: 73728
      N: 2048
      input_tensor_1_size: 1207959600.0
      output_tensor_size: 1207959600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1207959600.0
      shard_outer_M: 4608
      shard_K: 4608
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1207959600.0
    }
  }
  kernels {
    name: "Iteration_30"
    id: 30
    topological_number: 29
    config: 29
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 71680
      K: 71680
      N: 2048
      input_tensor_1_size: 1174405100.0
      output_tensor_size: 1174405100.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1174405100.0
      shard_outer_M: 4480
      shard_K: 4480
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1174405100.0
    }
  }
  kernels {
    name: "Iteration_31"
    id: 31
    topological_number: 30
    config: 30
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 69632
      K: 69632
      N: 2048
      input_tensor_1_size: 1140850700.0
      output_tensor_size: 1140850700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1140850700.0
      shard_outer_M: 4352
      shard_K: 4352
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1140850700.0
    }
  }
  kernels {
    name: "Iteration_32"
    id: 32
    topological_number: 31
    config: 31
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 67584
      K: 67584
      N: 2048
      input_tensor_1_size: 1107296300.0
      output_tensor_size: 1107296300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1107296300.0
      shard_outer_M: 4224
      shard_K: 4224
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1107296300.0
    }
  }
  kernels {
    name: "Iteration_33"
    id: 33
    topological_number: 32
    config: 32
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 65536
      K: 65536
      N: 2048
      input_tensor_1_size: 1073741800.0
      output_tensor_size: 1073741800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1073741800.0
      shard_outer_M: 4096
      shard_K: 4096
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1073741800.0
    }
  }
  kernels {
    name: "Iteration_34"
    id: 34
    topological_number: 33
    config: 33
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 63488
      K: 63488
      N: 2048
      input_tensor_1_size: 1040187400.0
      output_tensor_size: 1040187400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1040187400.0
      shard_outer_M: 3968
      shard_K: 3968
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1040187400.0
    }
  }
  kernels {
    name: "Iteration_35"
    id: 35
    topological_number: 34
    config: 34
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 61440
      K: 61440
      N: 2048
      input_tensor_1_size: 1006632960.0
      output_tensor_size: 1006632960.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1006632960.0
      shard_outer_M: 3840
      shard_K: 3840
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1006632960.0
    }
  }
  kernels {
    name: "Iteration_36"
    id: 36
    topological_number: 35
    config: 35
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 59392
      K: 59392
      N: 2048
      input_tensor_1_size: 973078500.0
      output_tensor_size: 973078500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 973078500.0
      shard_outer_M: 3712
      shard_K: 3712
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 973078500.0
    }
  }
  kernels {
    name: "Iteration_37"
    id: 37
    topological_number: 36
    config: 36
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 57344
      K: 57344
      N: 2048
      input_tensor_1_size: 939524100.0
      output_tensor_size: 939524100.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 939524100.0
      shard_outer_M: 3584
      shard_K: 3584
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 939524100.0
    }
  }
  kernels {
    name: "Iteration_38"
    id: 38
    topological_number: 37
    config: 37
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 55296
      K: 55296
      N: 2048
      input_tensor_1_size: 905969660.0
      output_tensor_size: 905969660.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 905969660.0
      shard_outer_M: 3456
      shard_K: 3456
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 905969660.0
    }
  }
  kernels {
    name: "Iteration_39"
    id: 39
    topological_number: 38
    config: 38
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 53248
      K: 53248
      N: 2048
      input_tensor_1_size: 872415200.0
      output_tensor_size: 872415200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 872415200.0
      shard_outer_M: 3328
      shard_K: 3328
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 872415200.0
    }
  }
  kernels {
    name: "Iteration_40"
    id: 40
    topological_number: 39
    config: 39
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 51200
      K: 51200
      N: 2048
      input_tensor_1_size: 838860800.0
      output_tensor_size: 838860800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 838860800.0
      shard_outer_M: 3200
      shard_K: 3200
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 838860800.0
    }
  }
  kernels {
    name: "Iteration_41"
    id: 41
    topological_number: 40
    config: 40
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 49152
      K: 49152
      N: 2048
      input_tensor_1_size: 805306400.0
      output_tensor_size: 805306400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 805306400.0
      shard_outer_M: 3072
      shard_K: 3072
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 805306400.0
    }
  }
  kernels {
    name: "Iteration_42"
    id: 42
    topological_number: 41
    config: 41
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 47104
      K: 47104
      N: 2048
      input_tensor_1_size: 771751940.0
      output_tensor_size: 771751940.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 771751940.0
      shard_outer_M: 2944
      shard_K: 2944
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 771751940.0
    }
  }
  kernels {
    name: "Iteration_43"
    id: 43
    topological_number: 42
    config: 42
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 45056
      K: 45056
      N: 2048
      input_tensor_1_size: 738197500.0
      output_tensor_size: 738197500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 738197500.0
      shard_outer_M: 2816
      shard_K: 2816
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 738197500.0
    }
  }
  kernels {
    name: "Iteration_44"
    id: 44
    topological_number: 43
    config: 43
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 43008
      K: 43008
      N: 2048
      input_tensor_1_size: 704643100.0
      output_tensor_size: 704643100.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 704643100.0
      shard_outer_M: 2688
      shard_K: 2688
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 704643100.0
    }
  }
  kernels {
    name: "Iteration_45"
    id: 45
    topological_number: 44
    config: 44
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 40960
      K: 40960
      N: 2048
      input_tensor_1_size: 671088640.0
      output_tensor_size: 671088640.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 671088640.0
      shard_outer_M: 2560
      shard_K: 2560
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 671088640.0
    }
  }
  kernels {
    name: "Iteration_46"
    id: 46
    topological_number: 45
    config: 45
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 38912
      K: 38912
      N: 2048
      input_tensor_1_size: 637534200.0
      output_tensor_size: 637534200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 637534200.0
      shard_outer_M: 2432
      shard_K: 2432
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 637534200.0
    }
  }
  kernels {
    name: "Iteration_47"
    id: 47
    topological_number: 46
    config: 46
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 36864
      K: 36864
      N: 2048
      input_tensor_1_size: 603979800.0
      output_tensor_size: 603979800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 603979800.0
      shard_outer_M: 2304
      shard_K: 2304
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 603979800.0
    }
  }
  kernels {
    name: "Iteration_48"
    id: 48
    topological_number: 47
    config: 47
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 34816
      K: 34816
      N: 2048
      input_tensor_1_size: 570425340.0
      output_tensor_size: 570425340.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 570425340.0
      shard_outer_M: 2176
      shard_K: 2176
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 570425340.0
    }
  }
  kernels {
    name: "Iteration_49"
    id: 49
    topological_number: 48
    config: 48
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 32768
      K: 32768
      N: 2048
      input_tensor_1_size: 536870900.0
      output_tensor_size: 536870900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 536870900.0
      shard_outer_M: 2048
      shard_K: 2048
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 536870900.0
    }
  }
  kernels {
    name: "Iteration_50"
    id: 50
    topological_number: 49
    config: 49
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 30720
      K: 30720
      N: 2048
      input_tensor_1_size: 503316480.0
      output_tensor_size: 503316480.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 503316480.0
      shard_outer_M: 1920
      shard_K: 1920
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 503316480.0
    }
  }
  kernels {
    name: "Iteration_51"
    id: 51
    topological_number: 50
    config: 50
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 28672
      K: 28672
      N: 2048
      input_tensor_1_size: 469762050.0
      output_tensor_size: 469762050.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 469762050.0
      shard_outer_M: 1792
      shard_K: 1792
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 469762050.0
    }
  }
  kernels {
    name: "Iteration_52"
    id: 52
    topological_number: 51
    config: 51
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 26624
      K: 26624
      N: 2048
      input_tensor_1_size: 436207600.0
      output_tensor_size: 436207600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 436207600.0
      shard_outer_M: 1664
      shard_K: 1664
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 436207600.0
    }
  }
  kernels {
    name: "Iteration_53"
    id: 53
    topological_number: 52
    config: 52
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 24576
      K: 24576
      N: 2048
      input_tensor_1_size: 402653200.0
      output_tensor_size: 402653200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 402653200.0
      shard_outer_M: 1536
      shard_K: 1536
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 402653200.0
    }
  }
  kernels {
    name: "Iteration_54"
    id: 54
    topological_number: 53
    config: 53
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 22528
      K: 22528
      N: 2048
      input_tensor_1_size: 369098750.0
      output_tensor_size: 369098750.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 369098750.0
      shard_outer_M: 1408
      shard_K: 1408
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 369098750.0
    }
  }
  kernels {
    name: "Iteration_55"
    id: 55
    topological_number: 54
    config: 54
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 20480
      K: 20480
      N: 2048
      input_tensor_1_size: 335544320.0
      output_tensor_size: 335544320.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 335544320.0
      shard_outer_M: 1280
      shard_K: 1280
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 335544320.0
    }
  }
  kernels {
    name: "Iteration_56"
    id: 56
    topological_number: 55
    config: 55
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 18432
      K: 18432
      N: 2048
      input_tensor_1_size: 301989900.0
      output_tensor_size: 301989900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 301989900.0
      shard_outer_M: 1152
      shard_K: 1559
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 301989900.0
    }
  }
  kernels {
    name: "Iteration_57"
    id: 57
    topological_number: 56
    config: 56
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 16384
      K: 16384
      N: 2048
      input_tensor_1_size: 268435460.0
      output_tensor_size: 268435460.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 268435460.0
      shard_outer_M: 1024
      shard_K: 1024
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 268435460.0
    }
  }
  kernels {
    name: "Iteration_58"
    id: 58
    topological_number: 57
    config: 57
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 14336
      K: 14336
      N: 2048
      input_tensor_1_size: 234881020.0
      output_tensor_size: 234881020.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 234881020.0
      shard_outer_M: 896
      shard_K: 922
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 234881020.0
    }
  }
  kernels {
    name: "Iteration_59"
    id: 59
    topological_number: 58
    config: 58
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 12288
      K: 12288
      N: 2048
      input_tensor_1_size: 201326600.0
      output_tensor_size: 201326600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 201326600.0
      shard_outer_M: 768
      shard_K: 768
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 201326600.0
    }
  }
  kernels {
    name: "Iteration_60"
    id: 60
    topological_number: 59
    config: 59
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 10240
      K: 10240
      N: 2048
      input_tensor_1_size: 167772160.0
      output_tensor_size: 167772160.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 167772160.0
      shard_outer_M: 640
      shard_K: 640
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 167772160.0
    }
  }
  kernels {
    name: "Iteration_61"
    id: 61
    topological_number: 60
    config: 60
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 8192
      K: 8192
      N: 2048
      input_tensor_1_size: 134217730.0
      output_tensor_size: 134217730.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 134217730.0
      shard_outer_M: 512
      shard_K: 512
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 134217730.0
    }
  }
  kernels {
    name: "Iteration_62"
    id: 62
    topological_number: 61
    config: 61
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 6144
      K: 6144
      N: 2048
      input_tensor_1_size: 100663300.0
      output_tensor_size: 100663300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 100663300.0
      shard_outer_M: 384
      shard_K: 384
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 100663300.0
    }
  }
  kernels {
    name: "Iteration_63"
    id: 63
    topological_number: 62
    config: 62
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 4096
      K: 4096
      N: 2048
      input_tensor_1_size: 67108864.0
      output_tensor_size: 67108864.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 67108864.0
      shard_outer_M: 256
      shard_K: 256
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 67108864.0
    }
  }
  kernels {
    name: "Iteration_64"
    id: 64
    topological_number: 63
    config: 63
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 2048
      K: 2048
      N: 2048
      input_tensor_1_size: 33554432.0
      output_tensor_size: 33554432.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 33554432.0
      shard_outer_M: 128
      shard_K: 128
      shard_N: 2048
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 33554432.0
    }
  }
  connections {
    startIdx: 1
    endIdx: 2
    buffer_depth: 2
    tensor_size: 2147483600.0
    shard_tensor_size: 134217730.0
    id: 1
    startName: "Iteration_1"
    endName: "Iteration_2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 2
    endIdx: 3
    buffer_depth: 2
    tensor_size: 2113929200.0
    shard_tensor_size: 132120580.0
    id: 2
    startName: "Iteration_2"
    endName: "Iteration_3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 3
    endIdx: 4
    buffer_depth: 2
    tensor_size: 2080374800.0
    shard_tensor_size: 130023420.0
    id: 3
    startName: "Iteration_3"
    endName: "Iteration_4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 4
    endIdx: 5
    buffer_depth: 2
    tensor_size: 2046820400.0
    shard_tensor_size: 127926270.0
    id: 4
    startName: "Iteration_4"
    endName: "Iteration_5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 5
    endIdx: 6
    buffer_depth: 2
    tensor_size: 2013265900.0
    shard_tensor_size: 125829120.0
    id: 5
    startName: "Iteration_5"
    endName: "Iteration_6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 6
    endIdx: 7
    buffer_depth: 2
    tensor_size: 1979711500.0
    shard_tensor_size: 123731970.0
    id: 6
    startName: "Iteration_6"
    endName: "Iteration_7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 7
    endIdx: 8
    buffer_depth: 2
    tensor_size: 1946157000.0
    shard_tensor_size: 121634820.0
    id: 7
    startName: "Iteration_7"
    endName: "Iteration_8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 8
    endIdx: 9
    buffer_depth: 2
    tensor_size: 1912602600.0
    shard_tensor_size: 119537660.0
    id: 8
    startName: "Iteration_8"
    endName: "Iteration_9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 9
    endIdx: 10
    buffer_depth: 2
    tensor_size: 1879048200.0
    shard_tensor_size: 117440510.0
    id: 9
    startName: "Iteration_9"
    endName: "Iteration_10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 10
    endIdx: 11
    buffer_depth: 2
    tensor_size: 1845493800.0
    shard_tensor_size: 115343360.0
    id: 10
    startName: "Iteration_10"
    endName: "Iteration_11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 11
    endIdx: 12
    buffer_depth: 2
    tensor_size: 1811939300.0
    shard_tensor_size: 113246210.0
    id: 11
    startName: "Iteration_11"
    endName: "Iteration_12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 12
    endIdx: 13
    buffer_depth: 2
    tensor_size: 1778384900.0
    shard_tensor_size: 111149060.0
    id: 12
    startName: "Iteration_12"
    endName: "Iteration_13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 13
    endIdx: 14
    buffer_depth: 2
    tensor_size: 1744830500.0
    shard_tensor_size: 109051900.0
    id: 13
    startName: "Iteration_13"
    endName: "Iteration_14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 14
    endIdx: 15
    buffer_depth: 2
    tensor_size: 1711276000.0
    shard_tensor_size: 106954750.0
    id: 14
    startName: "Iteration_14"
    endName: "Iteration_15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 15
    endIdx: 16
    buffer_depth: 2
    tensor_size: 1677721600.0
    shard_tensor_size: 104857600.0
    id: 15
    startName: "Iteration_15"
    endName: "Iteration_16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 16
    endIdx: 17
    buffer_depth: 2
    tensor_size: 1644167200.0
    shard_tensor_size: 102760450.0
    id: 16
    startName: "Iteration_16"
    endName: "Iteration_17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 17
    endIdx: 18
    buffer_depth: 2
    tensor_size: 1610612700.0
    shard_tensor_size: 100663300.0
    id: 17
    startName: "Iteration_17"
    endName: "Iteration_18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 18
    endIdx: 19
    buffer_depth: 2
    tensor_size: 1577058300.0
    shard_tensor_size: 98566140.0
    id: 18
    startName: "Iteration_18"
    endName: "Iteration_19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 19
    endIdx: 20
    buffer_depth: 2
    tensor_size: 1543503900.0
    shard_tensor_size: 96468990.0
    id: 19
    startName: "Iteration_19"
    endName: "Iteration_20"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 20
    endIdx: 21
    buffer_depth: 2
    tensor_size: 1509949400.0
    shard_tensor_size: 94371840.0
    id: 20
    startName: "Iteration_20"
    endName: "Iteration_21"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 21
    endIdx: 22
    buffer_depth: 2
    tensor_size: 1476395000.0
    shard_tensor_size: 92274690.0
    id: 21
    startName: "Iteration_21"
    endName: "Iteration_22"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 22
    endIdx: 23
    buffer_depth: 2
    tensor_size: 1442840600.0
    shard_tensor_size: 90177540.0
    id: 22
    startName: "Iteration_22"
    endName: "Iteration_23"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 23
    endIdx: 24
    buffer_depth: 2
    tensor_size: 1409286100.0
    shard_tensor_size: 88080380.0
    id: 23
    startName: "Iteration_23"
    endName: "Iteration_24"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 24
    endIdx: 25
    buffer_depth: 2
    tensor_size: 1375731700.0
    shard_tensor_size: 85983230.0
    id: 24
    startName: "Iteration_24"
    endName: "Iteration_25"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 25
    endIdx: 26
    buffer_depth: 2
    tensor_size: 1342177300.0
    shard_tensor_size: 83886080.0
    id: 25
    startName: "Iteration_25"
    endName: "Iteration_26"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 26
    endIdx: 27
    buffer_depth: 2
    tensor_size: 1308622800.0
    shard_tensor_size: 81788930.0
    id: 26
    startName: "Iteration_26"
    endName: "Iteration_27"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 27
    endIdx: 28
    buffer_depth: 2
    tensor_size: 1275068400.0
    shard_tensor_size: 79691780.0
    id: 27
    startName: "Iteration_27"
    endName: "Iteration_28"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 28
    endIdx: 29
    buffer_depth: 2
    tensor_size: 1241514000.0
    shard_tensor_size: 77594620.0
    id: 28
    startName: "Iteration_28"
    endName: "Iteration_29"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 29
    endIdx: 30
    buffer_depth: 2
    tensor_size: 1207959600.0
    shard_tensor_size: 75497470.0
    id: 29
    startName: "Iteration_29"
    endName: "Iteration_30"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 30
    endIdx: 31
    buffer_depth: 2
    tensor_size: 1174405100.0
    shard_tensor_size: 73400320.0
    id: 30
    startName: "Iteration_30"
    endName: "Iteration_31"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 31
    endIdx: 32
    buffer_depth: 2
    tensor_size: 1140850700.0
    shard_tensor_size: 71303170.0
    id: 31
    startName: "Iteration_31"
    endName: "Iteration_32"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 32
    endIdx: 33
    buffer_depth: 2
    tensor_size: 1107296300.0
    shard_tensor_size: 69206020.0
    id: 32
    startName: "Iteration_32"
    endName: "Iteration_33"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 33
    endIdx: 34
    buffer_depth: 2
    tensor_size: 1073741800.0
    shard_tensor_size: 67108864.0
    id: 33
    startName: "Iteration_33"
    endName: "Iteration_34"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 34
    endIdx: 35
    buffer_depth: 2
    tensor_size: 1040187400.0
    shard_tensor_size: 65011710.0
    id: 34
    startName: "Iteration_34"
    endName: "Iteration_35"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 35
    endIdx: 36
    buffer_depth: 2
    tensor_size: 1006632960.0
    shard_tensor_size: 62914560.0
    id: 35
    startName: "Iteration_35"
    endName: "Iteration_36"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 36
    endIdx: 37
    buffer_depth: 2
    tensor_size: 973078500.0
    shard_tensor_size: 60817410.0
    id: 36
    startName: "Iteration_36"
    endName: "Iteration_37"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 37
    endIdx: 38
    buffer_depth: 2
    tensor_size: 939524100.0
    shard_tensor_size: 58720256.0
    id: 37
    startName: "Iteration_37"
    endName: "Iteration_38"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 38
    endIdx: 39
    buffer_depth: 2
    tensor_size: 905969660.0
    shard_tensor_size: 56623104.0
    id: 38
    startName: "Iteration_38"
    endName: "Iteration_39"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 39
    endIdx: 40
    buffer_depth: 2
    tensor_size: 872415200.0
    shard_tensor_size: 54525950.0
    id: 39
    startName: "Iteration_39"
    endName: "Iteration_40"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 40
    endIdx: 41
    buffer_depth: 2
    tensor_size: 838860800.0
    shard_tensor_size: 52428800.0
    id: 40
    startName: "Iteration_40"
    endName: "Iteration_41"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 41
    endIdx: 42
    buffer_depth: 2
    tensor_size: 805306400.0
    shard_tensor_size: 50331650.0
    id: 41
    startName: "Iteration_41"
    endName: "Iteration_42"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 42
    endIdx: 43
    buffer_depth: 2
    tensor_size: 771751940.0
    shard_tensor_size: 48234496.0
    id: 42
    startName: "Iteration_42"
    endName: "Iteration_43"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 43
    endIdx: 44
    buffer_depth: 2
    tensor_size: 738197500.0
    shard_tensor_size: 46137344.0
    id: 43
    startName: "Iteration_43"
    endName: "Iteration_44"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 44
    endIdx: 45
    buffer_depth: 2
    tensor_size: 704643100.0
    shard_tensor_size: 44040190.0
    id: 44
    startName: "Iteration_44"
    endName: "Iteration_45"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 45
    endIdx: 46
    buffer_depth: 2
    tensor_size: 671088640.0
    shard_tensor_size: 41943040.0
    id: 45
    startName: "Iteration_45"
    endName: "Iteration_46"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 46
    endIdx: 47
    buffer_depth: 2
    tensor_size: 637534200.0
    shard_tensor_size: 39845890.0
    id: 46
    startName: "Iteration_46"
    endName: "Iteration_47"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 47
    endIdx: 48
    buffer_depth: 2
    tensor_size: 603979800.0
    shard_tensor_size: 37748736.0
    id: 47
    startName: "Iteration_47"
    endName: "Iteration_48"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 48
    endIdx: 49
    buffer_depth: 2
    tensor_size: 570425340.0
    shard_tensor_size: 35651584.0
    id: 48
    startName: "Iteration_48"
    endName: "Iteration_49"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 49
    endIdx: 50
    buffer_depth: 2
    tensor_size: 536870900.0
    shard_tensor_size: 33554432.0
    id: 49
    startName: "Iteration_49"
    endName: "Iteration_50"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 50
    endIdx: 51
    buffer_depth: 2
    tensor_size: 503316480.0
    shard_tensor_size: 31457280.0
    id: 50
    startName: "Iteration_50"
    endName: "Iteration_51"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 51
    endIdx: 52
    buffer_depth: 2
    tensor_size: 469762050.0
    shard_tensor_size: 29360128.0
    id: 51
    startName: "Iteration_51"
    endName: "Iteration_52"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 52
    endIdx: 53
    buffer_depth: 2
    tensor_size: 436207600.0
    shard_tensor_size: 27262976.0
    id: 52
    startName: "Iteration_52"
    endName: "Iteration_53"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 53
    endIdx: 54
    buffer_depth: 2
    tensor_size: 402653200.0
    shard_tensor_size: 25165824.0
    id: 53
    startName: "Iteration_53"
    endName: "Iteration_54"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 54
    endIdx: 55
    buffer_depth: 2
    tensor_size: 369098750.0
    shard_tensor_size: 23068672.0
    id: 54
    startName: "Iteration_54"
    endName: "Iteration_55"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 55
    endIdx: 56
    buffer_depth: 2
    tensor_size: 335544320.0
    shard_tensor_size: 20971520.0
    id: 55
    startName: "Iteration_55"
    endName: "Iteration_56"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 56
    endIdx: 57
    buffer_depth: 2
    tensor_size: 301989900.0
    shard_tensor_size: 18874368.0
    id: 56
    startName: "Iteration_56"
    endName: "Iteration_57"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 57
    endIdx: 58
    buffer_depth: 2
    tensor_size: 268435460.0
    shard_tensor_size: 16777216.0
    id: 57
    startName: "Iteration_57"
    endName: "Iteration_58"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 58
    endIdx: 59
    buffer_depth: 2
    tensor_size: 234881020.0
    shard_tensor_size: 14680064.0
    id: 58
    startName: "Iteration_58"
    endName: "Iteration_59"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 59
    endIdx: 60
    buffer_depth: 2
    tensor_size: 201326600.0
    shard_tensor_size: 12582912.0
    id: 59
    startName: "Iteration_59"
    endName: "Iteration_60"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 60
    endIdx: 61
    buffer_depth: 2
    tensor_size: 167772160.0
    shard_tensor_size: 10485760.0
    id: 60
    startName: "Iteration_60"
    endName: "Iteration_61"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 61
    endIdx: 62
    buffer_depth: 2
    tensor_size: 134217730.0
    shard_tensor_size: 8388608.0
    id: 61
    startName: "Iteration_61"
    endName: "Iteration_62"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 62
    endIdx: 63
    buffer_depth: 2
    tensor_size: 100663300.0
    shard_tensor_size: 6291456.0
    id: 62
    startName: "Iteration_62"
    endName: "Iteration_63"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 63
    endIdx: 64
    buffer_depth: 2
    tensor_size: 67108864.0
    shard_tensor_size: 4194304.0
    id: 63
    startName: "Iteration_63"
    endName: "Iteration_64"
    lane_stage_type: LANE
  }
}
system {
  num_chip: 256
  accelerator {
    core: 3456
    systolic_width: 1
    systolic_height: 1
    sram_cap: 230686720.0
    freq: 1.41
  }
  sw_sw {
    x: 16
    y: 16
    link_bw_x: 25.0
    link_bw_y: 25.0
  }
  memory {
    dram_bw: 1555.0
    dram_cap: 42949673000.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 33000.0
  link_unit_power_x: 0.0104
  link_unit_power_y: 0.0104
  switch_unit_power: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 750.0
}
execution {
  hpl {
    n: 131072
    b: 2048
    num_copy: 1
  }
  execution_style: KERNEL_BY_KERNEL
  overlap: PERFECT_OVERLAP
  word: 8
}
gurobi {
  gap: 0.001
  time: 180
}
