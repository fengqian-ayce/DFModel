dataflow_graph {
  kernels {
    name: "Iteration_1"
    id: 1
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 262144
      K: 262144
      N: 4096
      input_tensor_1_size: 8589935000.0
      output_tensor_size: 8589935000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 8589935000.0
      shard_outer_M: 2913
      shard_K: 2913
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 8589935000.0
    }
  }
  kernels {
    name: "Iteration_2"
    id: 2
    topological_number: 1
    config: 1
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 258048
      K: 258048
      N: 4096
      input_tensor_1_size: 8455717000.0
      output_tensor_size: 8455717000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 8455717000.0
      shard_outer_M: 2868
      shard_K: 2868
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 8455717000.0
    }
  }
  kernels {
    name: "Iteration_3"
    id: 3
    topological_number: 2
    config: 2
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 253952
      K: 253952
      N: 4096
      input_tensor_1_size: 8321499000.0
      output_tensor_size: 8321499000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 8321499000.0
      shard_outer_M: 2822
      shard_K: 2822
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 8321499000.0
    }
  }
  kernels {
    name: "Iteration_4"
    id: 4
    topological_number: 3
    config: 3
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 249856
      K: 249856
      N: 4096
      input_tensor_1_size: 8187281400.0
      output_tensor_size: 8187281400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 8187281400.0
      shard_outer_M: 2777
      shard_K: 2777
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 8187281400.0
    }
  }
  kernels {
    name: "Iteration_5"
    id: 5
    topological_number: 4
    config: 4
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 245760
      K: 245760
      N: 4096
      input_tensor_1_size: 8053063700.0
      output_tensor_size: 8053063700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 8053063700.0
      shard_outer_M: 2731
      shard_K: 2731
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 8053063700.0
    }
  }
  kernels {
    name: "Iteration_6"
    id: 6
    topological_number: 5
    config: 5
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 241664
      K: 241664
      N: 4096
      input_tensor_1_size: 7918846000.0
      output_tensor_size: 7918846000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7918846000.0
      shard_outer_M: 2686
      shard_K: 2686
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7918846000.0
    }
  }
  kernels {
    name: "Iteration_7"
    id: 7
    topological_number: 6
    config: 6
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 237568
      K: 237568
      N: 4096
      input_tensor_1_size: 7784628000.0
      output_tensor_size: 7784628000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7784628000.0
      shard_outer_M: 2640
      shard_K: 2640
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7784628000.0
    }
  }
  kernels {
    name: "Iteration_8"
    id: 8
    topological_number: 7
    config: 7
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 233472
      K: 233472
      N: 4096
      input_tensor_1_size: 7650410500.0
      output_tensor_size: 7650410500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7650410500.0
      shard_outer_M: 2595
      shard_K: 2595
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7650410500.0
    }
  }
  kernels {
    name: "Iteration_9"
    id: 9
    topological_number: 8
    config: 8
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 229376
      K: 229376
      N: 4096
      input_tensor_1_size: 7516193000.0
      output_tensor_size: 7516193000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7516193000.0
      shard_outer_M: 2549
      shard_K: 2549
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7516193000.0
    }
  }
  kernels {
    name: "Iteration_10"
    id: 10
    topological_number: 9
    config: 9
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 225280
      K: 225280
      N: 4096
      input_tensor_1_size: 7381975000.0
      output_tensor_size: 7381975000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7381975000.0
      shard_outer_M: 2504
      shard_K: 2504
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7381975000.0
    }
  }
  kernels {
    name: "Iteration_11"
    id: 11
    topological_number: 10
    config: 10
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 221184
      K: 221184
      N: 4096
      input_tensor_1_size: 7247757300.0
      output_tensor_size: 7247757300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7247757300.0
      shard_outer_M: 2458
      shard_K: 2458
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7247757300.0
    }
  }
  kernels {
    name: "Iteration_12"
    id: 12
    topological_number: 11
    config: 11
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 217088
      K: 217088
      N: 4096
      input_tensor_1_size: 7113539600.0
      output_tensor_size: 7113539600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 7113539600.0
      shard_outer_M: 2413
      shard_K: 2413
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 7113539600.0
    }
  }
  kernels {
    name: "Iteration_13"
    id: 13
    topological_number: 12
    config: 12
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 212992
      K: 212992
      N: 4096
      input_tensor_1_size: 6979322000.0
      output_tensor_size: 6979322000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6979322000.0
      shard_outer_M: 2367
      shard_K: 2367
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6979322000.0
    }
  }
  kernels {
    name: "Iteration_14"
    id: 14
    topological_number: 13
    config: 13
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 208896
      K: 208896
      N: 4096
      input_tensor_1_size: 6845104000.0
      output_tensor_size: 6845104000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6845104000.0
      shard_outer_M: 2322
      shard_K: 2322
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6845104000.0
    }
  }
  kernels {
    name: "Iteration_15"
    id: 15
    topological_number: 14
    config: 14
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 204800
      K: 204800
      N: 4096
      input_tensor_1_size: 6710886400.0
      output_tensor_size: 6710886400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6710886400.0
      shard_outer_M: 2276
      shard_K: 2276
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6710886400.0
    }
  }
  kernels {
    name: "Iteration_16"
    id: 16
    topological_number: 15
    config: 15
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 200704
      K: 200704
      N: 4096
      input_tensor_1_size: 6576668700.0
      output_tensor_size: 6576668700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6576668700.0
      shard_outer_M: 2231
      shard_K: 2231
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6576668700.0
    }
  }
  kernels {
    name: "Iteration_17"
    id: 17
    topological_number: 16
    config: 16
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 196608
      K: 196608
      N: 4096
      input_tensor_1_size: 6442451000.0
      output_tensor_size: 6442451000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6442451000.0
      shard_outer_M: 2185
      shard_K: 2185
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6442451000.0
    }
  }
  kernels {
    name: "Iteration_18"
    id: 18
    topological_number: 17
    config: 17
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 192512
      K: 192512
      N: 4096
      input_tensor_1_size: 6308233000.0
      output_tensor_size: 6308233000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6308233000.0
      shard_outer_M: 2140
      shard_K: 2140
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6308233000.0
    }
  }
  kernels {
    name: "Iteration_19"
    id: 19
    topological_number: 18
    config: 18
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 188416
      K: 188416
      N: 4096
      input_tensor_1_size: 6174015500.0
      output_tensor_size: 6174015500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6174015500.0
      shard_outer_M: 2094
      shard_K: 2094
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6174015500.0
    }
  }
  kernels {
    name: "Iteration_20"
    id: 20
    topological_number: 19
    config: 19
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 184320
      K: 184320
      N: 4096
      input_tensor_1_size: 6039798000.0
      output_tensor_size: 6039798000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 6039798000.0
      shard_outer_M: 2048
      shard_K: 2048
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 6039798000.0
    }
  }
  kernels {
    name: "Iteration_21"
    id: 21
    topological_number: 20
    config: 20
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 180224
      K: 180224
      N: 4096
      input_tensor_1_size: 5905580000.0
      output_tensor_size: 5905580000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5905580000.0
      shard_outer_M: 2003
      shard_K: 2003
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5905580000.0
    }
  }
  kernels {
    name: "Iteration_22"
    id: 22
    topological_number: 21
    config: 21
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 176128
      K: 176128
      N: 4096
      input_tensor_1_size: 5771362300.0
      output_tensor_size: 5771362300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5771362300.0
      shard_outer_M: 1957
      shard_K: 1957
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5771362300.0
    }
  }
  kernels {
    name: "Iteration_23"
    id: 23
    topological_number: 22
    config: 22
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 172032
      K: 172032
      N: 4096
      input_tensor_1_size: 5637144600.0
      output_tensor_size: 5637144600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5637144600.0
      shard_outer_M: 1912
      shard_K: 1912
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5637144600.0
    }
  }
  kernels {
    name: "Iteration_24"
    id: 24
    topological_number: 23
    config: 23
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 167936
      K: 167936
      N: 4096
      input_tensor_1_size: 5502927000.0
      output_tensor_size: 5502927000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5502927000.0
      shard_outer_M: 1866
      shard_K: 1866
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5502927000.0
    }
  }
  kernels {
    name: "Iteration_25"
    id: 25
    topological_number: 24
    config: 24
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 163840
      K: 163840
      N: 4096
      input_tensor_1_size: 5368709000.0
      output_tensor_size: 5368709000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5368709000.0
      shard_outer_M: 1821
      shard_K: 1821
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5368709000.0
    }
  }
  kernels {
    name: "Iteration_26"
    id: 26
    topological_number: 25
    config: 25
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 159744
      K: 159744
      N: 4096
      input_tensor_1_size: 5234491400.0
      output_tensor_size: 5234491400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5234491400.0
      shard_outer_M: 1775
      shard_K: 1775
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5234491400.0
    }
  }
  kernels {
    name: "Iteration_27"
    id: 27
    topological_number: 26
    config: 26
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 155648
      K: 155648
      N: 4096
      input_tensor_1_size: 5100273700.0
      output_tensor_size: 5100273700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 5100273700.0
      shard_outer_M: 1730
      shard_K: 1730
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 5100273700.0
    }
  }
  kernels {
    name: "Iteration_28"
    id: 28
    topological_number: 27
    config: 27
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 151552
      K: 151552
      N: 4096
      input_tensor_1_size: 4966056000.0
      output_tensor_size: 4966056000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4966056000.0
      shard_outer_M: 1684
      shard_K: 1684
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4966056000.0
    }
  }
  kernels {
    name: "Iteration_29"
    id: 29
    topological_number: 28
    config: 28
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 147456
      K: 147456
      N: 4096
      input_tensor_1_size: 4831838000.0
      output_tensor_size: 4831838000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4831838000.0
      shard_outer_M: 1639
      shard_K: 1639
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4831838000.0
    }
  }
  kernels {
    name: "Iteration_30"
    id: 30
    topological_number: 29
    config: 29
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 143360
      K: 143360
      N: 4096
      input_tensor_1_size: 4697620500.0
      output_tensor_size: 4697620500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4697620500.0
      shard_outer_M: 1593
      shard_K: 1593
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4697620500.0
    }
  }
  kernels {
    name: "Iteration_31"
    id: 31
    topological_number: 30
    config: 30
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 139264
      K: 139264
      N: 4096
      input_tensor_1_size: 4563403000.0
      output_tensor_size: 4563403000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4563403000.0
      shard_outer_M: 1548
      shard_K: 1548
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4563403000.0
    }
  }
  kernels {
    name: "Iteration_32"
    id: 32
    topological_number: 31
    config: 31
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 135168
      K: 135168
      N: 4096
      input_tensor_1_size: 4429185000.0
      output_tensor_size: 4429185000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4429185000.0
      shard_outer_M: 1502
      shard_K: 1502
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4429185000.0
    }
  }
  kernels {
    name: "Iteration_33"
    id: 33
    topological_number: 32
    config: 32
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 131072
      K: 131072
      N: 4096
      input_tensor_1_size: 4294967300.0
      output_tensor_size: 4294967300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4294967300.0
      shard_outer_M: 1457
      shard_K: 1457
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4294967300.0
    }
  }
  kernels {
    name: "Iteration_34"
    id: 34
    topological_number: 33
    config: 33
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 126976
      K: 126976
      N: 4096
      input_tensor_1_size: 4160749600.0
      output_tensor_size: 4160749600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4160749600.0
      shard_outer_M: 1411
      shard_K: 1411
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4160749600.0
    }
  }
  kernels {
    name: "Iteration_35"
    id: 35
    topological_number: 34
    config: 34
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 122880
      K: 122880
      N: 4096
      input_tensor_1_size: 4026531800.0
      output_tensor_size: 4026531800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 4026531800.0
      shard_outer_M: 1366
      shard_K: 1366
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 4026531800.0
    }
  }
  kernels {
    name: "Iteration_36"
    id: 36
    topological_number: 35
    config: 35
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 118784
      K: 118784
      N: 4096
      input_tensor_1_size: 3892314000.0
      output_tensor_size: 3892314000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3892314000.0
      shard_outer_M: 1320
      shard_K: 1320
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3892314000.0
    }
  }
  kernels {
    name: "Iteration_37"
    id: 37
    topological_number: 36
    config: 36
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 114688
      K: 114688
      N: 4096
      input_tensor_1_size: 3758096400.0
      output_tensor_size: 3758096400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3758096400.0
      shard_outer_M: 1275
      shard_K: 1275
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3758096400.0
    }
  }
  kernels {
    name: "Iteration_38"
    id: 38
    topological_number: 37
    config: 37
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 110592
      K: 110592
      N: 4096
      input_tensor_1_size: 3623878700.0
      output_tensor_size: 3623878700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3623878700.0
      shard_outer_M: 1229
      shard_K: 1229
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3623878700.0
    }
  }
  kernels {
    name: "Iteration_39"
    id: 39
    topological_number: 38
    config: 38
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 106496
      K: 106496
      N: 4096
      input_tensor_1_size: 3489661000.0
      output_tensor_size: 3489661000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3489661000.0
      shard_outer_M: 1184
      shard_K: 1184
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3489661000.0
    }
  }
  kernels {
    name: "Iteration_40"
    id: 40
    topological_number: 39
    config: 39
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 102400
      K: 102400
      N: 4096
      input_tensor_1_size: 3355443200.0
      output_tensor_size: 3355443200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3355443200.0
      shard_outer_M: 1138
      shard_K: 1138
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3355443200.0
    }
  }
  kernels {
    name: "Iteration_41"
    id: 41
    topological_number: 40
    config: 40
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 98304
      K: 98304
      N: 4096
      input_tensor_1_size: 3221225500.0
      output_tensor_size: 3221225500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3221225500.0
      shard_outer_M: 1093
      shard_K: 1093
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3221225500.0
    }
  }
  kernels {
    name: "Iteration_42"
    id: 42
    topological_number: 41
    config: 41
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 94208
      K: 94208
      N: 4096
      input_tensor_1_size: 3087007700.0
      output_tensor_size: 3087007700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 3087007700.0
      shard_outer_M: 1047
      shard_K: 1047
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 3087007700.0
    }
  }
  kernels {
    name: "Iteration_43"
    id: 43
    topological_number: 42
    config: 42
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 90112
      K: 90112
      N: 4096
      input_tensor_1_size: 2952790000.0
      output_tensor_size: 2952790000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2952790000.0
      shard_outer_M: 1002
      shard_K: 1002
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2952790000.0
    }
  }
  kernels {
    name: "Iteration_44"
    id: 44
    topological_number: 43
    config: 43
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 86016
      K: 86016
      N: 4096
      input_tensor_1_size: 2818572300.0
      output_tensor_size: 2818572300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2818572300.0
      shard_outer_M: 956
      shard_K: 956
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2818572300.0
    }
  }
  kernels {
    name: "Iteration_45"
    id: 45
    topological_number: 44
    config: 44
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 81920
      K: 81920
      N: 4096
      input_tensor_1_size: 2684354600.0
      output_tensor_size: 2684354600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2684354600.0
      shard_outer_M: 911
      shard_K: 911
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2684354600.0
    }
  }
  kernels {
    name: "Iteration_46"
    id: 46
    topological_number: 45
    config: 45
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 77824
      K: 77824
      N: 4096
      input_tensor_1_size: 2550136800.0
      output_tensor_size: 2550136800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2550136800.0
      shard_outer_M: 865
      shard_K: 865
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2550136800.0
    }
  }
  kernels {
    name: "Iteration_47"
    id: 47
    topological_number: 46
    config: 46
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 73728
      K: 73728
      N: 4096
      input_tensor_1_size: 2415919000.0
      output_tensor_size: 2415919000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2415919000.0
      shard_outer_M: 820
      shard_K: 820
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2415919000.0
    }
  }
  kernels {
    name: "Iteration_48"
    id: 48
    topological_number: 47
    config: 47
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 69632
      K: 69632
      N: 4096
      input_tensor_1_size: 2281701400.0
      output_tensor_size: 2281701400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2281701400.0
      shard_outer_M: 774
      shard_K: 774
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2281701400.0
    }
  }
  kernels {
    name: "Iteration_49"
    id: 49
    topological_number: 48
    config: 48
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 65536
      K: 65536
      N: 4096
      input_tensor_1_size: 2147483600.0
      output_tensor_size: 2147483600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2147483600.0
      shard_outer_M: 729
      shard_K: 729
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2147483600.0
    }
  }
  kernels {
    name: "Iteration_50"
    id: 50
    topological_number: 49
    config: 49
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 61440
      K: 61440
      N: 4096
      input_tensor_1_size: 2013265900.0
      output_tensor_size: 2013265900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 2013265900.0
      shard_outer_M: 683
      shard_K: 683
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 2013265900.0
    }
  }
  kernels {
    name: "Iteration_51"
    id: 51
    topological_number: 50
    config: 50
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 57344
      K: 57344
      N: 4096
      input_tensor_1_size: 1879048200.0
      output_tensor_size: 1879048200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1879048200.0
      shard_outer_M: 638
      shard_K: 638
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1879048200.0
    }
  }
  kernels {
    name: "Iteration_52"
    id: 52
    topological_number: 51
    config: 51
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 53248
      K: 53248
      N: 4096
      input_tensor_1_size: 1744830500.0
      output_tensor_size: 1744830500.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1744830500.0
      shard_outer_M: 592
      shard_K: 592
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1744830500.0
    }
  }
  kernels {
    name: "Iteration_53"
    id: 53
    topological_number: 52
    config: 52
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 49152
      K: 49152
      N: 4096
      input_tensor_1_size: 1610612700.0
      output_tensor_size: 1610612700.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1610612700.0
      shard_outer_M: 547
      shard_K: 547
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1610612700.0
    }
  }
  kernels {
    name: "Iteration_54"
    id: 54
    topological_number: 53
    config: 53
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 45056
      K: 45056
      N: 4096
      input_tensor_1_size: 1476395000.0
      output_tensor_size: 1476395000.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1476395000.0
      shard_outer_M: 501
      shard_K: 501
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1476395000.0
    }
  }
  kernels {
    name: "Iteration_55"
    id: 55
    topological_number: 54
    config: 54
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 40960
      K: 40960
      N: 4096
      input_tensor_1_size: 1342177300.0
      output_tensor_size: 1342177300.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1342177300.0
      shard_outer_M: 456
      shard_K: 456
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1342177300.0
    }
  }
  kernels {
    name: "Iteration_56"
    id: 56
    topological_number: 55
    config: 55
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 36864
      K: 36864
      N: 4096
      input_tensor_1_size: 1207959600.0
      output_tensor_size: 1207959600.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1207959600.0
      shard_outer_M: 410
      shard_K: 410
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1207959600.0
    }
  }
  kernels {
    name: "Iteration_57"
    id: 57
    topological_number: 56
    config: 56
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 32768
      K: 32768
      N: 4096
      input_tensor_1_size: 1073741800.0
      output_tensor_size: 1073741800.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 1073741800.0
      shard_outer_M: 365
      shard_K: 365
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 1073741800.0
    }
  }
  kernels {
    name: "Iteration_58"
    id: 58
    topological_number: 57
    config: 57
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 28672
      K: 28672
      N: 4096
      input_tensor_1_size: 939524100.0
      output_tensor_size: 939524100.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 939524100.0
      shard_outer_M: 319
      shard_K: 319
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 939524100.0
    }
  }
  kernels {
    name: "Iteration_59"
    id: 59
    topological_number: 58
    config: 58
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 24576
      K: 24576
      N: 4096
      input_tensor_1_size: 805306400.0
      output_tensor_size: 805306400.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 805306400.0
      shard_outer_M: 274
      shard_K: 274
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 805306400.0
    }
  }
  kernels {
    name: "Iteration_60"
    id: 60
    topological_number: 59
    config: 59
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 20480
      K: 20480
      N: 4096
      input_tensor_1_size: 671088640.0
      output_tensor_size: 671088640.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 671088640.0
      shard_outer_M: 228
      shard_K: 228
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 671088640.0
    }
  }
  kernels {
    name: "Iteration_61"
    id: 61
    topological_number: 60
    config: 60
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 16384
      K: 16384
      N: 4096
      input_tensor_1_size: 536870900.0
      output_tensor_size: 536870900.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 536870900.0
      shard_outer_M: 183
      shard_K: 183
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 536870900.0
    }
  }
  kernels {
    name: "Iteration_62"
    id: 62
    topological_number: 61
    config: 61
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 12288
      K: 12288
      N: 4096
      input_tensor_1_size: 402653200.0
      output_tensor_size: 402653200.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 402653200.0
      shard_outer_M: 137
      shard_K: 137
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 402653200.0
    }
  }
  kernels {
    name: "Iteration_63"
    id: 63
    topological_number: 62
    config: 62
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 8192
      K: 8192
      N: 4096
      input_tensor_1_size: 268435460.0
      output_tensor_size: 268435460.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 268435460.0
      shard_outer_M: 92
      shard_K: 92
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 268435460.0
    }
  }
  kernels {
    name: "Iteration_64"
    id: 64
    topological_number: 63
    config: 63
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 4096
      K: 4096
      N: 4096
      input_tensor_1_size: 134217730.0
      output_tensor_size: 134217730.0
      sharding: NO_SHARDING
      communication_type: BROADCAST
      communication_size: 134217730.0
      shard_outer_M: 46
      shard_K: 46
      shard_N: 4096
      tiling: NO_TILING
      communication_type_2: POINT_TO_POINT
      communication_size_2: 134217730.0
    }
  }
  connections {
    startIdx: 1
    endIdx: 2
    buffer_depth: 2
    tensor_size: 8589935000.0
    shard_tensor_size: 95453180.0
    id: 1
    startName: "Iteration_1"
    endName: "Iteration_2"
  }
  connections {
    startIdx: 2
    endIdx: 3
    buffer_depth: 2
    tensor_size: 8455717000.0
    shard_tensor_size: 93978620.0
    id: 2
    startName: "Iteration_2"
    endName: "Iteration_3"
  }
  connections {
    startIdx: 3
    endIdx: 4
    buffer_depth: 2
    tensor_size: 8321499000.0
    shard_tensor_size: 92471300.0
    id: 3
    startName: "Iteration_3"
    endName: "Iteration_4"
  }
  connections {
    startIdx: 4
    endIdx: 5
    buffer_depth: 2
    tensor_size: 8187281400.0
    shard_tensor_size: 90996740.0
    id: 4
    startName: "Iteration_4"
    endName: "Iteration_5"
  }
  connections {
    startIdx: 5
    endIdx: 6
    buffer_depth: 2
    tensor_size: 8053063700.0
    shard_tensor_size: 89489410.0
    id: 5
    startName: "Iteration_5"
    endName: "Iteration_6"
  }
  connections {
    startIdx: 6
    endIdx: 7
    buffer_depth: 2
    tensor_size: 7918846000.0
    shard_tensor_size: 88014850.0
    id: 6
    startName: "Iteration_6"
    endName: "Iteration_7"
  }
  connections {
    startIdx: 7
    endIdx: 8
    buffer_depth: 2
    tensor_size: 7784628000.0
    shard_tensor_size: 86507520.0
    id: 7
    startName: "Iteration_7"
    endName: "Iteration_8"
  }
  connections {
    startIdx: 8
    endIdx: 9
    buffer_depth: 2
    tensor_size: 7650410500.0
    shard_tensor_size: 85032960.0
    id: 8
    startName: "Iteration_8"
    endName: "Iteration_9"
  }
  connections {
    startIdx: 9
    endIdx: 10
    buffer_depth: 2
    tensor_size: 7516193000.0
    shard_tensor_size: 83525630.0
    id: 9
    startName: "Iteration_9"
    endName: "Iteration_10"
  }
  connections {
    startIdx: 10
    endIdx: 11
    buffer_depth: 2
    tensor_size: 7381975000.0
    shard_tensor_size: 82051070.0
    id: 10
    startName: "Iteration_10"
    endName: "Iteration_11"
  }
  connections {
    startIdx: 11
    endIdx: 12
    buffer_depth: 2
    tensor_size: 7247757300.0
    shard_tensor_size: 80543740.0
    id: 11
    startName: "Iteration_11"
    endName: "Iteration_12"
  }
  connections {
    startIdx: 12
    endIdx: 13
    buffer_depth: 2
    tensor_size: 7113539600.0
    shard_tensor_size: 79069180.0
    id: 12
    startName: "Iteration_12"
    endName: "Iteration_13"
  }
  connections {
    startIdx: 13
    endIdx: 14
    buffer_depth: 2
    tensor_size: 6979322000.0
    shard_tensor_size: 77561860.0
    id: 13
    startName: "Iteration_13"
    endName: "Iteration_14"
  }
  connections {
    startIdx: 14
    endIdx: 15
    buffer_depth: 2
    tensor_size: 6845104000.0
    shard_tensor_size: 76087300.0
    id: 14
    startName: "Iteration_14"
    endName: "Iteration_15"
  }
  connections {
    startIdx: 15
    endIdx: 16
    buffer_depth: 2
    tensor_size: 6710886400.0
    shard_tensor_size: 74579970.0
    id: 15
    startName: "Iteration_15"
    endName: "Iteration_16"
  }
  connections {
    startIdx: 16
    endIdx: 17
    buffer_depth: 2
    tensor_size: 6576668700.0
    shard_tensor_size: 73105410.0
    id: 16
    startName: "Iteration_16"
    endName: "Iteration_17"
  }
  connections {
    startIdx: 17
    endIdx: 18
    buffer_depth: 2
    tensor_size: 6442451000.0
    shard_tensor_size: 71598080.0
    id: 17
    startName: "Iteration_17"
    endName: "Iteration_18"
  }
  connections {
    startIdx: 18
    endIdx: 19
    buffer_depth: 2
    tensor_size: 6308233000.0
    shard_tensor_size: 70123520.0
    id: 18
    startName: "Iteration_18"
    endName: "Iteration_19"
  }
  connections {
    startIdx: 19
    endIdx: 20
    buffer_depth: 2
    tensor_size: 6174015500.0
    shard_tensor_size: 68616190.0
    id: 19
    startName: "Iteration_19"
    endName: "Iteration_20"
  }
  connections {
    startIdx: 20
    endIdx: 21
    buffer_depth: 2
    tensor_size: 6039798000.0
    shard_tensor_size: 67108864.0
    id: 20
    startName: "Iteration_20"
    endName: "Iteration_21"
  }
  connections {
    startIdx: 21
    endIdx: 22
    buffer_depth: 2
    tensor_size: 5905580000.0
    shard_tensor_size: 65634304.0
    id: 21
    startName: "Iteration_21"
    endName: "Iteration_22"
  }
  connections {
    startIdx: 22
    endIdx: 23
    buffer_depth: 2
    tensor_size: 5771362300.0
    shard_tensor_size: 64126976.0
    id: 22
    startName: "Iteration_22"
    endName: "Iteration_23"
  }
  connections {
    startIdx: 23
    endIdx: 24
    buffer_depth: 2
    tensor_size: 5637144600.0
    shard_tensor_size: 62652416.0
    id: 23
    startName: "Iteration_23"
    endName: "Iteration_24"
  }
  connections {
    startIdx: 24
    endIdx: 25
    buffer_depth: 2
    tensor_size: 5502927000.0
    shard_tensor_size: 61145090.0
    id: 24
    startName: "Iteration_24"
    endName: "Iteration_25"
  }
  connections {
    startIdx: 25
    endIdx: 26
    buffer_depth: 2
    tensor_size: 5368709000.0
    shard_tensor_size: 59670530.0
    id: 25
    startName: "Iteration_25"
    endName: "Iteration_26"
  }
  connections {
    startIdx: 26
    endIdx: 27
    buffer_depth: 2
    tensor_size: 5234491400.0
    shard_tensor_size: 58163200.0
    id: 26
    startName: "Iteration_26"
    endName: "Iteration_27"
  }
  connections {
    startIdx: 27
    endIdx: 28
    buffer_depth: 2
    tensor_size: 5100273700.0
    shard_tensor_size: 56688640.0
    id: 27
    startName: "Iteration_27"
    endName: "Iteration_28"
  }
  connections {
    startIdx: 28
    endIdx: 29
    buffer_depth: 2
    tensor_size: 4966056000.0
    shard_tensor_size: 55181310.0
    id: 28
    startName: "Iteration_28"
    endName: "Iteration_29"
  }
  connections {
    startIdx: 29
    endIdx: 30
    buffer_depth: 2
    tensor_size: 4831838000.0
    shard_tensor_size: 53706750.0
    id: 29
    startName: "Iteration_29"
    endName: "Iteration_30"
  }
  connections {
    startIdx: 30
    endIdx: 31
    buffer_depth: 2
    tensor_size: 4697620500.0
    shard_tensor_size: 52199424.0
    id: 30
    startName: "Iteration_30"
    endName: "Iteration_31"
  }
  connections {
    startIdx: 31
    endIdx: 32
    buffer_depth: 2
    tensor_size: 4563403000.0
    shard_tensor_size: 50724864.0
    id: 31
    startName: "Iteration_31"
    endName: "Iteration_32"
  }
  connections {
    startIdx: 32
    endIdx: 33
    buffer_depth: 2
    tensor_size: 4429185000.0
    shard_tensor_size: 49217536.0
    id: 32
    startName: "Iteration_32"
    endName: "Iteration_33"
  }
  connections {
    startIdx: 33
    endIdx: 34
    buffer_depth: 2
    tensor_size: 4294967300.0
    shard_tensor_size: 47742976.0
    id: 33
    startName: "Iteration_33"
    endName: "Iteration_34"
  }
  connections {
    startIdx: 34
    endIdx: 35
    buffer_depth: 2
    tensor_size: 4160749600.0
    shard_tensor_size: 46235650.0
    id: 34
    startName: "Iteration_34"
    endName: "Iteration_35"
  }
  connections {
    startIdx: 35
    endIdx: 36
    buffer_depth: 2
    tensor_size: 4026531800.0
    shard_tensor_size: 44761090.0
    id: 35
    startName: "Iteration_35"
    endName: "Iteration_36"
  }
  connections {
    startIdx: 36
    endIdx: 37
    buffer_depth: 2
    tensor_size: 3892314000.0
    shard_tensor_size: 43253760.0
    id: 36
    startName: "Iteration_36"
    endName: "Iteration_37"
  }
  connections {
    startIdx: 37
    endIdx: 38
    buffer_depth: 2
    tensor_size: 3758096400.0
    shard_tensor_size: 41779200.0
    id: 37
    startName: "Iteration_37"
    endName: "Iteration_38"
  }
  connections {
    startIdx: 38
    endIdx: 39
    buffer_depth: 2
    tensor_size: 3623878700.0
    shard_tensor_size: 40271870.0
    id: 38
    startName: "Iteration_38"
    endName: "Iteration_39"
  }
  connections {
    startIdx: 39
    endIdx: 40
    buffer_depth: 2
    tensor_size: 3489661000.0
    shard_tensor_size: 38797310.0
    id: 39
    startName: "Iteration_39"
    endName: "Iteration_40"
  }
  connections {
    startIdx: 40
    endIdx: 41
    buffer_depth: 2
    tensor_size: 3355443200.0
    shard_tensor_size: 37289984.0
    id: 40
    startName: "Iteration_40"
    endName: "Iteration_41"
  }
  connections {
    startIdx: 41
    endIdx: 42
    buffer_depth: 2
    tensor_size: 3221225500.0
    shard_tensor_size: 35815424.0
    id: 41
    startName: "Iteration_41"
    endName: "Iteration_42"
  }
  connections {
    startIdx: 42
    endIdx: 43
    buffer_depth: 2
    tensor_size: 3087007700.0
    shard_tensor_size: 34308096.0
    id: 42
    startName: "Iteration_42"
    endName: "Iteration_43"
  }
  connections {
    startIdx: 43
    endIdx: 44
    buffer_depth: 2
    tensor_size: 2952790000.0
    shard_tensor_size: 32833536.0
    id: 43
    startName: "Iteration_43"
    endName: "Iteration_44"
  }
  connections {
    startIdx: 44
    endIdx: 45
    buffer_depth: 2
    tensor_size: 2818572300.0
    shard_tensor_size: 31326208.0
    id: 44
    startName: "Iteration_44"
    endName: "Iteration_45"
  }
  connections {
    startIdx: 45
    endIdx: 46
    buffer_depth: 2
    tensor_size: 2684354600.0
    shard_tensor_size: 29851648.0
    id: 45
    startName: "Iteration_45"
    endName: "Iteration_46"
  }
  connections {
    startIdx: 46
    endIdx: 47
    buffer_depth: 2
    tensor_size: 2550136800.0
    shard_tensor_size: 28344320.0
    id: 46
    startName: "Iteration_46"
    endName: "Iteration_47"
  }
  connections {
    startIdx: 47
    endIdx: 48
    buffer_depth: 2
    tensor_size: 2415919000.0
    shard_tensor_size: 26869760.0
    id: 47
    startName: "Iteration_47"
    endName: "Iteration_48"
  }
  connections {
    startIdx: 48
    endIdx: 49
    buffer_depth: 2
    tensor_size: 2281701400.0
    shard_tensor_size: 25362432.0
    id: 48
    startName: "Iteration_48"
    endName: "Iteration_49"
  }
  connections {
    startIdx: 49
    endIdx: 50
    buffer_depth: 2
    tensor_size: 2147483600.0
    shard_tensor_size: 23887872.0
    id: 49
    startName: "Iteration_49"
    endName: "Iteration_50"
  }
  connections {
    startIdx: 50
    endIdx: 51
    buffer_depth: 2
    tensor_size: 2013265900.0
    shard_tensor_size: 22380544.0
    id: 50
    startName: "Iteration_50"
    endName: "Iteration_51"
  }
  connections {
    startIdx: 51
    endIdx: 52
    buffer_depth: 2
    tensor_size: 1879048200.0
    shard_tensor_size: 20905984.0
    id: 51
    startName: "Iteration_51"
    endName: "Iteration_52"
  }
  connections {
    startIdx: 52
    endIdx: 53
    buffer_depth: 2
    tensor_size: 1744830500.0
    shard_tensor_size: 19398656.0
    id: 52
    startName: "Iteration_52"
    endName: "Iteration_53"
  }
  connections {
    startIdx: 53
    endIdx: 54
    buffer_depth: 2
    tensor_size: 1610612700.0
    shard_tensor_size: 17924096.0
    id: 53
    startName: "Iteration_53"
    endName: "Iteration_54"
  }
  connections {
    startIdx: 54
    endIdx: 55
    buffer_depth: 2
    tensor_size: 1476395000.0
    shard_tensor_size: 16416768.0
    id: 54
    startName: "Iteration_54"
    endName: "Iteration_55"
  }
  connections {
    startIdx: 55
    endIdx: 56
    buffer_depth: 2
    tensor_size: 1342177300.0
    shard_tensor_size: 14942208.0
    id: 55
    startName: "Iteration_55"
    endName: "Iteration_56"
  }
  connections {
    startIdx: 56
    endIdx: 57
    buffer_depth: 2
    tensor_size: 1207959600.0
    shard_tensor_size: 13434880.0
    id: 56
    startName: "Iteration_56"
    endName: "Iteration_57"
  }
  connections {
    startIdx: 57
    endIdx: 58
    buffer_depth: 2
    tensor_size: 1073741800.0
    shard_tensor_size: 11960320.0
    id: 57
    startName: "Iteration_57"
    endName: "Iteration_58"
  }
  connections {
    startIdx: 58
    endIdx: 59
    buffer_depth: 2
    tensor_size: 939524100.0
    shard_tensor_size: 10452992.0
    id: 58
    startName: "Iteration_58"
    endName: "Iteration_59"
  }
  connections {
    startIdx: 59
    endIdx: 60
    buffer_depth: 2
    tensor_size: 805306400.0
    shard_tensor_size: 8978432.0
    id: 59
    startName: "Iteration_59"
    endName: "Iteration_60"
  }
  connections {
    startIdx: 60
    endIdx: 61
    buffer_depth: 2
    tensor_size: 671088640.0
    shard_tensor_size: 7471104.0
    id: 60
    startName: "Iteration_60"
    endName: "Iteration_61"
  }
  connections {
    startIdx: 61
    endIdx: 62
    buffer_depth: 2
    tensor_size: 536870900.0
    shard_tensor_size: 5996544.0
    id: 61
    startName: "Iteration_61"
    endName: "Iteration_62"
  }
  connections {
    startIdx: 62
    endIdx: 63
    buffer_depth: 2
    tensor_size: 402653200.0
    shard_tensor_size: 4489216.0
    id: 62
    startName: "Iteration_62"
    endName: "Iteration_63"
  }
  connections {
    startIdx: 63
    endIdx: 64
    buffer_depth: 2
    tensor_size: 268435460.0
    shard_tensor_size: 3014656.0
    id: 63
    startName: "Iteration_63"
    endName: "Iteration_64"
  }
}
system {
  num_chip: 8100
  accelerator {
    core: 3456
    systolic_width: 1
    systolic_height: 1
    sram_cap: 230686720.0
    freq: 1.41
  }
  sw_sw {
    x: 90
    y: 90
    link_bw_x: 25.0
    link_bw_y: 25.0
  }
  memory {
    dram_bw: 1555.0
    dram_cap: 42949673000.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 33000.0
  link_unit_power_x: 0.0104
  link_unit_power_y: 0.0104
  switch_unit_power: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 750.0
}
miscellany {
  hpl {
    n: 262144
    b: 4096
    num_copy: 1
  }
  execution_style: KERNEL_BY_KERNEL
  perfect_overlap: true
  compute_util: 0.9
  word: 8
}
gurobi {
  thread: 144
  gap: 0.001
  time: 180
}
