dataflow_graph {
  kernels {
    name: "Q"
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 2
      M: 16
      K: 32
      N: 1048576
      input_tensor_size: 67108864.0
      weight_tensor_size: 2048.0
      output_tensor_size: 67108864.0
      sharding: NO_SHARDING
      tiling: N_TILING
    }
  }
  kernels {
    name: "K"
    id: 1
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 2
      M: 16
      K: 32
      N: 1048576
      input_tensor_size: 67108864.0
      weight_tensor_size: 2048.0
      output_tensor_size: 67108864.0
      sharding: NO_SHARDING
      tiling: N_TILING
    }
  }
  kernels {
    name: "V"
    id: 2
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 2
      M: 16
      K: 32
      N: 1048576
      input_tensor_size: 67108864.0
      weight_tensor_size: 2048.0
      output_tensor_size: 67108864.0
      sharding: NO_SHARDING
      tiling: N_TILING
    }
  }
  kernels {
    name: "Q_stage0"
    id: 3
    topological_number: 1
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage1"
    id: 4
    topological_number: 2
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage2"
    id: 5
    topological_number: 3
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage3"
    id: 6
    topological_number: 4
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage4"
    id: 7
    topological_number: 5
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage5"
    id: 8
    topological_number: 6
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage6"
    id: 9
    topological_number: 7
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage7"
    id: 10
    topological_number: 8
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage8"
    id: 11
    topological_number: 9
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage9"
    id: 12
    topological_number: 10
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage10"
    id: 13
    topological_number: 11
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage11"
    id: 14
    topological_number: 12
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage12"
    id: 15
    topological_number: 13
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage13"
    id: 16
    topological_number: 14
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage14"
    id: 17
    topological_number: 15
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage15"
    id: 18
    topological_number: 16
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage16"
    id: 19
    topological_number: 17
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage17"
    id: 20
    topological_number: 18
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage18"
    id: 21
    topological_number: 19
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "Q_stage19"
    id: 22
    topological_number: 20
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage0"
    id: 23
    topological_number: 1
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage1"
    id: 24
    topological_number: 2
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage2"
    id: 25
    topological_number: 3
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage3"
    id: 26
    topological_number: 4
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage4"
    id: 27
    topological_number: 5
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage5"
    id: 28
    topological_number: 6
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage6"
    id: 29
    topological_number: 7
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage7"
    id: 30
    topological_number: 8
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage8"
    id: 31
    topological_number: 9
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage9"
    id: 32
    topological_number: 10
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage10"
    id: 33
    topological_number: 11
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage11"
    id: 34
    topological_number: 12
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage12"
    id: 35
    topological_number: 13
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage13"
    id: 36
    topological_number: 14
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage14"
    id: 37
    topological_number: 15
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage15"
    id: 38
    topological_number: 16
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage16"
    id: 39
    topological_number: 17
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage17"
    id: 40
    topological_number: 18
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage18"
    id: 41
    topological_number: 19
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "K_stage19"
    id: 42
    topological_number: 20
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage0"
    id: 43
    topological_number: 22
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage1"
    id: 44
    topological_number: 23
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage2"
    id: 45
    topological_number: 24
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage3"
    id: 46
    topological_number: 25
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage4"
    id: 47
    topological_number: 26
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage5"
    id: 48
    topological_number: 27
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage6"
    id: 49
    topological_number: 28
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage7"
    id: 50
    topological_number: 29
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage8"
    id: 51
    topological_number: 30
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage9"
    id: 52
    topological_number: 31
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage10"
    id: 53
    topological_number: 32
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage11"
    id: 54
    topological_number: 33
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage12"
    id: 55
    topological_number: 34
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage13"
    id: 56
    topological_number: 35
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage14"
    id: 57
    topological_number: 36
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage15"
    id: 58
    topological_number: 37
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage16"
    id: 59
    topological_number: 38
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage17"
    id: 60
    topological_number: 39
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage18"
    id: 61
    topological_number: 40
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKi_stage19"
    id: 62
    topological_number: 41
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage0"
    id: 63
    topological_number: 43
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage1"
    id: 64
    topological_number: 44
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage2"
    id: 65
    topological_number: 45
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage3"
    id: 66
    topological_number: 46
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage4"
    id: 67
    topological_number: 47
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage5"
    id: 68
    topological_number: 48
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage6"
    id: 69
    topological_number: 49
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage7"
    id: 70
    topological_number: 50
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage8"
    id: 71
    topological_number: 51
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage9"
    id: 72
    topological_number: 52
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage10"
    id: 73
    topological_number: 53
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage11"
    id: 74
    topological_number: 54
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage12"
    id: 75
    topological_number: 55
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage13"
    id: 76
    topological_number: 56
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage14"
    id: 77
    topological_number: 57
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage15"
    id: 78
    topological_number: 58
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage16"
    id: 79
    topological_number: 59
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage17"
    id: 80
    topological_number: 60
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage18"
    id: 81
    topological_number: 61
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "inter_stage19"
    id: 82
    topological_number: 62
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage0"
    id: 83
    topological_number: 1
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage1"
    id: 84
    topological_number: 2
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage2"
    id: 85
    topological_number: 3
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage3"
    id: 86
    topological_number: 4
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage4"
    id: 87
    topological_number: 5
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage5"
    id: 88
    topological_number: 6
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage6"
    id: 89
    topological_number: 7
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage7"
    id: 90
    topological_number: 8
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage8"
    id: 91
    topological_number: 9
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage9"
    id: 92
    topological_number: 10
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage10"
    id: 93
    topological_number: 11
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage11"
    id: 94
    topological_number: 12
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage12"
    id: 95
    topological_number: 13
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage13"
    id: 96
    topological_number: 14
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage14"
    id: 97
    topological_number: 15
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage15"
    id: 98
    topological_number: 16
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage16"
    id: 99
    topological_number: 17
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage17"
    id: 100
    topological_number: 18
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage18"
    id: 101
    topological_number: 19
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "V_stage19"
    id: 102
    topological_number: 20
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage0"
    id: 103
    topological_number: 64
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage1"
    id: 104
    topological_number: 65
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage2"
    id: 105
    topological_number: 66
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage3"
    id: 106
    topological_number: 67
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage4"
    id: 107
    topological_number: 68
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage5"
    id: 108
    topological_number: 69
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage6"
    id: 109
    topological_number: 70
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage7"
    id: 110
    topological_number: 71
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage8"
    id: 111
    topological_number: 72
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage9"
    id: 112
    topological_number: 73
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage10"
    id: 113
    topological_number: 74
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage11"
    id: 114
    topological_number: 75
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage12"
    id: 115
    topological_number: 76
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage13"
    id: 116
    topological_number: 77
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage14"
    id: 117
    topological_number: 78
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage15"
    id: 118
    topological_number: 79
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage16"
    id: 119
    topological_number: 80
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage17"
    id: 120
    topological_number: 81
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage18"
    id: 121
    topological_number: 82
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "interVi_stage19"
    id: 122
    topological_number: 83
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 2
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      skip_weight: true
      num_input: 32
      sram_extra: 4194304.0
      dram_extra: 4194304.0
    }
  }
  kernels {
    name: "QKmultiply"
    id: 123
    topological_number: 21
    config: -1
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 32
    }
  }
  kernels {
    name: "softmax"
    id: 124
    topological_number: 42
    config: -1
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 32
    }
  }
  kernels {
    name: "interVmultiply"
    id: 125
    topological_number: 63
    config: -1
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 32
    }
  }
  kernels {
    name: "FFN0"
    id: 126
    topological_number: 84
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 128
      K: 32
      N: 1048576
      input_tensor_size: 67108864.0
      weight_tensor_size: 8192.0
      output_tensor_size: 268435460.0
      sharding: NO_SHARDING
      tiling: N_TILING
    }
  }
  kernels {
    name: "FFN1"
    id: 127
    topological_number: 85
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 32
      K: 128
      N: 1048576
      input_tensor_size: 268435460.0
      weight_tensor_size: 8192.0
      output_tensor_size: 67108864.0
      sharding: NO_SHARDING
      tiling: N_TILING
    }
  }
  connections {
    startIdx: 3
    endIdx: 4
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 3
    startName: "Q_stage0"
    endName: "Q_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 4
    endIdx: 5
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 4
    startName: "Q_stage1"
    endName: "Q_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 5
    endIdx: 6
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 5
    startName: "Q_stage2"
    endName: "Q_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 6
    endIdx: 7
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 6
    startName: "Q_stage3"
    endName: "Q_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 7
    endIdx: 8
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 7
    startName: "Q_stage4"
    endName: "Q_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 8
    endIdx: 9
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 8
    startName: "Q_stage5"
    endName: "Q_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 9
    endIdx: 10
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 9
    startName: "Q_stage6"
    endName: "Q_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 10
    endIdx: 11
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 10
    startName: "Q_stage7"
    endName: "Q_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 11
    endIdx: 12
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 11
    startName: "Q_stage8"
    endName: "Q_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 12
    endIdx: 13
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 12
    startName: "Q_stage9"
    endName: "Q_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 13
    endIdx: 14
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 13
    startName: "Q_stage10"
    endName: "Q_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 14
    endIdx: 15
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 14
    startName: "Q_stage11"
    endName: "Q_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 15
    endIdx: 16
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 15
    startName: "Q_stage12"
    endName: "Q_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 16
    endIdx: 17
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 16
    startName: "Q_stage13"
    endName: "Q_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 17
    endIdx: 18
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 17
    startName: "Q_stage14"
    endName: "Q_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 18
    endIdx: 19
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 18
    startName: "Q_stage15"
    endName: "Q_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 19
    endIdx: 20
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 19
    startName: "Q_stage16"
    endName: "Q_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 20
    endIdx: 21
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 20
    startName: "Q_stage17"
    endName: "Q_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 21
    endIdx: 22
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 21
    startName: "Q_stage18"
    endName: "Q_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 23
    endIdx: 24
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 23
    startName: "K_stage0"
    endName: "K_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 24
    endIdx: 25
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 24
    startName: "K_stage1"
    endName: "K_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 25
    endIdx: 26
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 25
    startName: "K_stage2"
    endName: "K_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 26
    endIdx: 27
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 26
    startName: "K_stage3"
    endName: "K_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 27
    endIdx: 28
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 27
    startName: "K_stage4"
    endName: "K_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 28
    endIdx: 29
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 28
    startName: "K_stage5"
    endName: "K_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 29
    endIdx: 30
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 29
    startName: "K_stage6"
    endName: "K_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 30
    endIdx: 31
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 30
    startName: "K_stage7"
    endName: "K_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 31
    endIdx: 32
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 31
    startName: "K_stage8"
    endName: "K_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 32
    endIdx: 33
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 32
    startName: "K_stage9"
    endName: "K_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 33
    endIdx: 34
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 33
    startName: "K_stage10"
    endName: "K_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 34
    endIdx: 35
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 34
    startName: "K_stage11"
    endName: "K_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 35
    endIdx: 36
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 35
    startName: "K_stage12"
    endName: "K_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 36
    endIdx: 37
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 36
    startName: "K_stage13"
    endName: "K_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 37
    endIdx: 38
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 37
    startName: "K_stage14"
    endName: "K_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 38
    endIdx: 39
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 38
    startName: "K_stage15"
    endName: "K_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 39
    endIdx: 40
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 39
    startName: "K_stage16"
    endName: "K_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 40
    endIdx: 41
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 40
    startName: "K_stage17"
    endName: "K_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 41
    endIdx: 42
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 41
    startName: "K_stage18"
    endName: "K_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 43
    endIdx: 44
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 43
    startName: "QKi_stage0"
    endName: "QKi_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 44
    endIdx: 45
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 44
    startName: "QKi_stage1"
    endName: "QKi_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 45
    endIdx: 46
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 45
    startName: "QKi_stage2"
    endName: "QKi_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 46
    endIdx: 47
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 46
    startName: "QKi_stage3"
    endName: "QKi_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 47
    endIdx: 48
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 47
    startName: "QKi_stage4"
    endName: "QKi_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 48
    endIdx: 49
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 48
    startName: "QKi_stage5"
    endName: "QKi_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 49
    endIdx: 50
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 49
    startName: "QKi_stage6"
    endName: "QKi_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 50
    endIdx: 51
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 50
    startName: "QKi_stage7"
    endName: "QKi_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 51
    endIdx: 52
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 51
    startName: "QKi_stage8"
    endName: "QKi_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 52
    endIdx: 53
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 52
    startName: "QKi_stage9"
    endName: "QKi_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 53
    endIdx: 54
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 53
    startName: "QKi_stage10"
    endName: "QKi_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 54
    endIdx: 55
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 54
    startName: "QKi_stage11"
    endName: "QKi_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 55
    endIdx: 56
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 55
    startName: "QKi_stage12"
    endName: "QKi_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 56
    endIdx: 57
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 56
    startName: "QKi_stage13"
    endName: "QKi_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 57
    endIdx: 58
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 57
    startName: "QKi_stage14"
    endName: "QKi_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 58
    endIdx: 59
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 58
    startName: "QKi_stage15"
    endName: "QKi_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 59
    endIdx: 60
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 59
    startName: "QKi_stage16"
    endName: "QKi_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 60
    endIdx: 61
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 60
    startName: "QKi_stage17"
    endName: "QKi_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 61
    endIdx: 62
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 61
    startName: "QKi_stage18"
    endName: "QKi_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 63
    endIdx: 64
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 63
    startName: "inter_stage0"
    endName: "inter_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 64
    endIdx: 65
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 64
    startName: "inter_stage1"
    endName: "inter_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 65
    endIdx: 66
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 65
    startName: "inter_stage2"
    endName: "inter_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 66
    endIdx: 67
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 66
    startName: "inter_stage3"
    endName: "inter_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 67
    endIdx: 68
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 67
    startName: "inter_stage4"
    endName: "inter_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 68
    endIdx: 69
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 68
    startName: "inter_stage5"
    endName: "inter_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 69
    endIdx: 70
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 69
    startName: "inter_stage6"
    endName: "inter_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 70
    endIdx: 71
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 70
    startName: "inter_stage7"
    endName: "inter_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 71
    endIdx: 72
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 71
    startName: "inter_stage8"
    endName: "inter_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 72
    endIdx: 73
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 72
    startName: "inter_stage9"
    endName: "inter_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 73
    endIdx: 74
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 73
    startName: "inter_stage10"
    endName: "inter_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 74
    endIdx: 75
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 74
    startName: "inter_stage11"
    endName: "inter_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 75
    endIdx: 76
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 75
    startName: "inter_stage12"
    endName: "inter_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 76
    endIdx: 77
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 76
    startName: "inter_stage13"
    endName: "inter_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 77
    endIdx: 78
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 77
    startName: "inter_stage14"
    endName: "inter_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 78
    endIdx: 79
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 78
    startName: "inter_stage15"
    endName: "inter_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 79
    endIdx: 80
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 79
    startName: "inter_stage16"
    endName: "inter_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 80
    endIdx: 81
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 80
    startName: "inter_stage17"
    endName: "inter_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 81
    endIdx: 82
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 81
    startName: "inter_stage18"
    endName: "inter_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 83
    endIdx: 84
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 83
    startName: "V_stage0"
    endName: "V_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 84
    endIdx: 85
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 84
    startName: "V_stage1"
    endName: "V_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 85
    endIdx: 86
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 85
    startName: "V_stage2"
    endName: "V_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 86
    endIdx: 87
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 86
    startName: "V_stage3"
    endName: "V_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 87
    endIdx: 88
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 87
    startName: "V_stage4"
    endName: "V_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 88
    endIdx: 89
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 88
    startName: "V_stage5"
    endName: "V_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 89
    endIdx: 90
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 89
    startName: "V_stage6"
    endName: "V_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 90
    endIdx: 91
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 90
    startName: "V_stage7"
    endName: "V_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 91
    endIdx: 92
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 91
    startName: "V_stage8"
    endName: "V_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 92
    endIdx: 93
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 92
    startName: "V_stage9"
    endName: "V_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 93
    endIdx: 94
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 93
    startName: "V_stage10"
    endName: "V_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 94
    endIdx: 95
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 94
    startName: "V_stage11"
    endName: "V_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 95
    endIdx: 96
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 95
    startName: "V_stage12"
    endName: "V_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 96
    endIdx: 97
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 96
    startName: "V_stage13"
    endName: "V_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 97
    endIdx: 98
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 97
    startName: "V_stage14"
    endName: "V_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 98
    endIdx: 99
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 98
    startName: "V_stage15"
    endName: "V_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 99
    endIdx: 100
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 99
    startName: "V_stage16"
    endName: "V_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 100
    endIdx: 101
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 100
    startName: "V_stage17"
    endName: "V_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 101
    endIdx: 102
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 101
    startName: "V_stage18"
    endName: "V_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 103
    endIdx: 104
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 103
    startName: "interVi_stage0"
    endName: "interVi_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 104
    endIdx: 105
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 104
    startName: "interVi_stage1"
    endName: "interVi_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 105
    endIdx: 106
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 105
    startName: "interVi_stage2"
    endName: "interVi_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 106
    endIdx: 107
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 106
    startName: "interVi_stage3"
    endName: "interVi_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 107
    endIdx: 108
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 107
    startName: "interVi_stage4"
    endName: "interVi_stage5"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 108
    endIdx: 109
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 108
    startName: "interVi_stage5"
    endName: "interVi_stage6"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 109
    endIdx: 110
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 109
    startName: "interVi_stage6"
    endName: "interVi_stage7"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 110
    endIdx: 111
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 110
    startName: "interVi_stage7"
    endName: "interVi_stage8"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 111
    endIdx: 112
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 111
    startName: "interVi_stage8"
    endName: "interVi_stage9"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 112
    endIdx: 113
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 112
    startName: "interVi_stage9"
    endName: "interVi_stage10"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 113
    endIdx: 114
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 113
    startName: "interVi_stage10"
    endName: "interVi_stage11"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 114
    endIdx: 115
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 114
    startName: "interVi_stage11"
    endName: "interVi_stage12"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 115
    endIdx: 116
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 115
    startName: "interVi_stage12"
    endName: "interVi_stage13"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 116
    endIdx: 117
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 116
    startName: "interVi_stage13"
    endName: "interVi_stage14"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 117
    endIdx: 118
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 117
    startName: "interVi_stage14"
    endName: "interVi_stage15"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 118
    endIdx: 119
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 118
    startName: "interVi_stage15"
    endName: "interVi_stage16"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 119
    endIdx: 120
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 119
    startName: "interVi_stage16"
    endName: "interVi_stage17"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 120
    endIdx: 121
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 120
    startName: "interVi_stage17"
    endName: "interVi_stage18"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 121
    endIdx: 122
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 121
    startName: "interVi_stage18"
    endName: "interVi_stage19"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 22
    endIdx: 123
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 200
    startName: "Q_stage19"
    endName: "QKmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 42
    endIdx: 123
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 201
    startName: "K_stage19"
    endName: "QKmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 123
    endIdx: 43
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 202
    startName: "QKmultiply"
    endName: "QKi_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 62
    endIdx: 124
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 203
    startName: "QKi_stage19"
    endName: "softmax"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 124
    endIdx: 63
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 204
    startName: "softmax"
    endName: "inter_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 82
    endIdx: 125
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 205
    startName: "inter_stage19"
    endName: "interVmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 102
    endIdx: 125
    buffer_depth: 44
    tensor_size: 4194304.0
    id: 206
    startName: "V_stage19"
    endName: "interVmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 125
    endIdx: 103
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 207
    startName: "interVmultiply"
    endName: "interVi_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 122
    endIdx: 126
    buffer_depth: 2
    tensor_size: 4194304.0
    id: 208
    startName: "interVi_stage19"
    endName: "FFN0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 126
    endIdx: 127
    buffer_depth: 2
    tensor_size: 268435460.0
    id: 209
    startName: "FFN0"
    endName: "FFN1"
    lane_stage_type: LANE
  }
  connections {
    endIdx: 3
    buffer_depth: 2
    tensor_size: 67108864.0
    id: 210
    startName: "Q"
    endName: "Q_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 1
    endIdx: 23
    buffer_depth: 2
    tensor_size: 67108864.0
    id: 211
    startName: "K"
    endName: "K_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 2
    endIdx: 83
    buffer_depth: 2
    tensor_size: 67108864.0
    id: 212
    startName: "V"
    endName: "V_stage0"
    lane_stage_type: LANE
  }
}
system {
  num_chip: 1
  accelerator {
    core: 520
    systolic_width: 32
    systolic_height: 12
    freq: 1.6
  }
  r {
    x: 1
    link_bw_x: 10.0
    par_x: "DP"
  }
  memory {
    dram_bw: 8192.0
    dram_cap: 103079215000.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 16522.25
  link_unit_power_x: 0.052
  link_unit_power_y: 0.052
  switch_unit_power: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 444.7062
}
execution {
  llm {
    hidden_dim: 32
    head_dim: 16
    num_head: 2
    seq_len: 1048576
    num_layer: 1
    global_batch_size: 1
    micro_batch_size: 1
    tile_size: 1048576
    num_layer_in_graph: 1
  }
  execution_style: DATAFLOW
  num_config: 3
  overlap: PERFECT_OVERLAP
  word: 2
  skip_inter_chip_optimization: true
}
gurobi {
  gap: 0.001
  time: 180
}
