dataflow_graph {
  kernels {
    name: "Q_stage0"
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "Q_stage1"
    id: 1
    topological_number: 1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "Q_stage2"
    id: 2
    topological_number: 2
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "Q_stage3"
    id: 3
    topological_number: 3
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "Q_stage4"
    id: 4
    topological_number: 4
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "K_stage0"
    id: 5
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "K_stage1"
    id: 6
    topological_number: 1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "K_stage2"
    id: 7
    topological_number: 2
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "K_stage3"
    id: 8
    topological_number: 3
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "K_stage4"
    id: 9
    topological_number: 4
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKi_stage0"
    id: 10
    topological_number: 6
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKi_stage1"
    id: 11
    topological_number: 7
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKi_stage2"
    id: 12
    topological_number: 8
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKi_stage3"
    id: 13
    topological_number: 9
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKi_stage4"
    id: 14
    topological_number: 10
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "inter_stage0"
    id: 15
    topological_number: 12
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "inter_stage1"
    id: 16
    topological_number: 13
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "inter_stage2"
    id: 17
    topological_number: 14
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "inter_stage3"
    id: 18
    topological_number: 15
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "inter_stage4"
    id: 19
    topological_number: 16
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "V_stage0"
    id: 20
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "V_stage1"
    id: 21
    topological_number: 1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "V_stage2"
    id: 22
    topological_number: 2
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "V_stage3"
    id: 23
    topological_number: 3
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "V_stage4"
    id: 24
    topological_number: 4
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "interVi_stage0"
    id: 25
    topological_number: 18
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "interVi_stage1"
    id: 26
    topological_number: 19
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "interVi_stage2"
    id: 27
    topological_number: 20
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "interVi_stage3"
    id: 28
    topological_number: 21
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "interVi_stage4"
    id: 29
    topological_number: 22
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 2097152
      K: 8
      N: 1
      input_tensor_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_K: 8
      shard_N: 1
      tiling: NO_TILING
      skip_weight: true
      use_effective_stage: true
      num_input: 1
    }
  }
  kernels {
    name: "QKmultiply"
    id: 30
    topological_number: 5
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_N: 1
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 1
    }
  }
  kernels {
    name: "softmax"
    id: 31
    topological_number: 11
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_N: 1
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 1
    }
  }
  kernels {
    name: "interVmultiply"
    id: 32
    topological_number: 17
    fwd_bwd: FWD
    type: SIMD
    elementwise_input1_input2 {
      outer: 1
      M: 2097152
      N: 1
      input_tensor_1_size: 4194304.0
      output_tensor_size: 4194304.0
      sharding: NO_SHARDING
      shard_outer_M: 2097152
      shard_N: 1
      tiling: NO_TILING
      input_tensor_2_size: 4194304.0
      num_input: 1
    }
  }
  connections {
    endIdx: 1
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    startName: "Q_stage0"
    endName: "Q_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 1
    endIdx: 2
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 1
    startName: "Q_stage1"
    endName: "Q_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 2
    endIdx: 3
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 2
    startName: "Q_stage2"
    endName: "Q_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 3
    endIdx: 4
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 3
    startName: "Q_stage3"
    endName: "Q_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 5
    endIdx: 6
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 5
    startName: "K_stage0"
    endName: "K_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 6
    endIdx: 7
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 6
    startName: "K_stage1"
    endName: "K_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 7
    endIdx: 8
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 7
    startName: "K_stage2"
    endName: "K_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 8
    endIdx: 9
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 8
    startName: "K_stage3"
    endName: "K_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 10
    endIdx: 11
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 10
    startName: "QKi_stage0"
    endName: "QKi_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 11
    endIdx: 12
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 11
    startName: "QKi_stage1"
    endName: "QKi_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 12
    endIdx: 13
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 12
    startName: "QKi_stage2"
    endName: "QKi_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 13
    endIdx: 14
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 13
    startName: "QKi_stage3"
    endName: "QKi_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 15
    endIdx: 16
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 15
    startName: "inter_stage0"
    endName: "inter_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 16
    endIdx: 17
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 16
    startName: "inter_stage1"
    endName: "inter_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 17
    endIdx: 18
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 17
    startName: "inter_stage2"
    endName: "inter_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 18
    endIdx: 19
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 18
    startName: "inter_stage3"
    endName: "inter_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 20
    endIdx: 21
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 20
    startName: "V_stage0"
    endName: "V_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 21
    endIdx: 22
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 21
    startName: "V_stage1"
    endName: "V_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 22
    endIdx: 23
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 22
    startName: "V_stage2"
    endName: "V_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 23
    endIdx: 24
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 23
    startName: "V_stage3"
    endName: "V_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 25
    endIdx: 26
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 25
    startName: "interVi_stage0"
    endName: "interVi_stage1"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 26
    endIdx: 27
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 26
    startName: "interVi_stage1"
    endName: "interVi_stage2"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 27
    endIdx: 28
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 27
    startName: "interVi_stage2"
    endName: "interVi_stage3"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 28
    endIdx: 29
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 28
    startName: "interVi_stage3"
    endName: "interVi_stage4"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 4
    endIdx: 30
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 50
    startName: "Q_stage4"
    endName: "QKmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 9
    endIdx: 30
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 51
    startName: "K_stage4"
    endName: "QKmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 30
    endIdx: 10
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 52
    startName: "QKmultiply"
    endName: "QKi_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 14
    endIdx: 31
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 53
    startName: "QKi_stage4"
    endName: "softmax"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 31
    endIdx: 15
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 54
    startName: "softmax"
    endName: "inter_stage0"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 19
    endIdx: 32
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 55
    startName: "inter_stage4"
    endName: "interVmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 24
    endIdx: 32
    buffer_depth: 14
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 56
    startName: "V_stage4"
    endName: "interVmultiply"
    lane_stage_type: LANE
  }
  connections {
    startIdx: 32
    endIdx: 25
    buffer_depth: 2
    tensor_size: 4194304.0
    shard_tensor_size: 4194304.0
    id: 57
    startName: "interVmultiply"
    endName: "interVi_stage0"
    lane_stage_type: LANE
  }
}
system {
  num_chip: 1
  accelerator {
    core: 520
    systolic_width: 32
    systolic_height: 12
    sram_cap: 545259500.0
    freq: 1.6
  }
  r_r_r {
    x: 1
    y: 1
    z: 1
    link_bw_x: 50.0
    link_bw_y: 50.0
    link_bw_z: 50.0
    par_x: "TP"
    par_y: "PP"
    par_z: "DP"
  }
  memory {
    dram_bw: 3072.0
    dram_cap: 103079215000.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 16522.25
  link_unit_power_x: 0.052
  link_unit_power_y: 0.052
  switch_unit_power: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 444.7062
}
execution {
  vector_fft_llm {
    hidden: 1
    seq_len: 1048576
    effective_stage: 8
  }
  execution_style: DATAFLOW
  num_config: 1
  perfect_overlap: true
  word: 2
}
gurobi {
  thread: 144
  gap: 0.001
  time: 36000
}
