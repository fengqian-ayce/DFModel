dataflow_graph {
	kernels {
  name: "MLP_1"
  id: 1
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2"
  id: 2
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_3"
  id: 3
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4"
  id: 4
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_5"
  id: 5
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6"
  id: 6
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7"
  id: 7
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8"
  id: 8
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_9"
  id: 9
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_10"
  id: 10
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_11"
  id: 11
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_12"
  id: 12
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_13"
  id: 13
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    communication_type: ALL_TO_ALL
    communication_size: 10304000.0
    tiling: NO_TILING
    memory_size: 1318912000.0
  }
}
kernels {
  name: "MLP_14"
  id: 14
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_15"
  id: 15
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_16"
  id: 16
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_17"
  id: 17
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_18"
  id: 18
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_19"
  id: 19
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_20"
  id: 20
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_21"
  id: 21
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_22"
  id: 22
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_23"
  id: 23
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_24"
  id: 24
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_25"
  id: 25
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_26"
  id: 26
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_27"
  id: 27
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_28"
  id: 28
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_29"
  id: 29
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_30"
  id: 30
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_31"
  id: 31
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_32"
  id: 32
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_33"
  id: 33
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_34"
  id: 34
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_35"
  id: 35
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_36"
  id: 36
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_37"
  id: 37
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_38"
  id: 38
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_39"
  id: 39
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_40"
  id: 40
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_41"
  id: 41
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_42"
  id: 42
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_43"
  id: 43
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_43_bwd"
  id: 44
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_42_bwd"
  id: 45
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_41_bwd"
  id: 46
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_40_bwd"
  id: 47
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_39_bwd"
  id: 48
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_38_bwd"
  id: 49
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_37_bwd"
  id: 50
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_36_bwd"
  id: 51
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_35_bwd"
  id: 52
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_34_bwd"
  id: 53
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_33_bwd"
  id: 54
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_32_bwd"
  id: 55
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_31_bwd"
  id: 56
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_30_bwd"
  id: 57
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_29_bwd"
  id: 58
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_28_bwd"
  id: 59
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_27_bwd"
  id: 60
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_26_bwd"
  id: 61
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_25_bwd"
  id: 62
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_24_bwd"
  id: 63
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_23_bwd"
  id: 64
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_22_bwd"
  id: 65
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_21_bwd"
  id: 66
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_20_bwd"
  id: 67
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_19_bwd"
  id: 68
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_18_bwd"
  id: 69
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_17_bwd"
  id: 70
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_16_bwd"
  id: 71
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_15_bwd"
  id: 72
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_14_bwd"
  id: 73
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_13_bwd"
  id: 74
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    communication_type: ALL_TO_ALL
    communication_size: 10304000.0
    tiling: NO_TILING
    memory_size: 1318912000.0
  }
}
kernels {
  name: "MLP_12_bwd"
  id: 75
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_11_bwd"
  id: 76
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_10_bwd"
  id: 77
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_9_bwd"
  id: 78
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8_bwd"
  id: 79
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7_bwd"
  id: 80
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6_bwd"
  id: 81
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_5_bwd"
  id: 82
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4_bwd"
  id: 83
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_3_bwd"
  id: 84
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2_bwd"
  id: 85
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_1_bwd"
  id: 86
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 682
    K: 682
    N: 2048
    input_tensor_size: 2793472.0
    weight_tensor_size: 930248.0
    output_tensor_size: 2793472.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_43_bwd_weight_update"
  id: 87
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_42_bwd_weight_update"
  id: 88
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_41_bwd_weight_update"
  id: 89
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_40_bwd_weight_update"
  id: 90
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_39_bwd_weight_update"
  id: 91
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_38_bwd_weight_update"
  id: 92
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_37_bwd_weight_update"
  id: 93
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_36_bwd_weight_update"
  id: 94
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_35_bwd_weight_update"
  id: 95
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_34_bwd_weight_update"
  id: 96
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_33_bwd_weight_update"
  id: 97
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_32_bwd_weight_update"
  id: 98
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_31_bwd_weight_update"
  id: 99
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_30_bwd_weight_update"
  id: 100
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_29_bwd_weight_update"
  id: 101
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_28_bwd_weight_update"
  id: 102
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_27_bwd_weight_update"
  id: 103
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_26_bwd_weight_update"
  id: 104
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_25_bwd_weight_update"
  id: 105
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_24_bwd_weight_update"
  id: 106
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_23_bwd_weight_update"
  id: 107
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_22_bwd_weight_update"
  id: 108
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_21_bwd_weight_update"
  id: 109
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_20_bwd_weight_update"
  id: 110
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_19_bwd_weight_update"
  id: 111
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_18_bwd_weight_update"
  id: 112
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_17_bwd_weight_update"
  id: 113
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_16_bwd_weight_update"
  id: 114
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_15_bwd_weight_update"
  id: 115
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_14_bwd_weight_update"
  id: 116
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_13_bwd_weight_update"
  id: 117
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_12_bwd_weight_update"
  id: 118
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_11_bwd_weight_update"
  id: 119
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_10_bwd_weight_update"
  id: 120
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_9_bwd_weight_update"
  id: 121
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8_bwd_weight_update"
  id: 122
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7_bwd_weight_update"
  id: 123
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6_bwd_weight_update"
  id: 124
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_5_bwd_weight_update"
  id: 125
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4_bwd_weight_update"
  id: 126
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_3_bwd_weight_update"
  id: 127
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2_bwd_weight_update"
  id: 128
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_1_bwd_weight_update"
  id: 129
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 682
    K: 2048
    N: 682
    input_tensor_1_size: 2793472.0
    input_tensor_2_size: 2793472.0
    output_tensor_size: 930248.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 930248.0
    tiling: NO_TILING
  }
}
connections {
  startIdx: 1
  endIdx: 2
  id: 1
}
connections {
  startIdx: 2
  endIdx: 3
  id: 2
}
connections {
  startIdx: 3
  endIdx: 4
  id: 3
}
connections {
  startIdx: 4
  endIdx: 5
  id: 4
}
connections {
  startIdx: 5
  endIdx: 6
  id: 5
}
connections {
  startIdx: 6
  endIdx: 7
  id: 6
}
connections {
  startIdx: 7
  endIdx: 8
  id: 7
}
connections {
  startIdx: 8
  endIdx: 9
  id: 8
}
connections {
  startIdx: 9
  endIdx: 10
  id: 9
}
connections {
  startIdx: 10
  endIdx: 11
  id: 10
}
connections {
  startIdx: 11
  endIdx: 12
  id: 11
}
connections {
  startIdx: 12
  endIdx: 13
  id: 12
}
connections {
  startIdx: 13
  endIdx: 14
  id: 13
}
connections {
  startIdx: 14
  endIdx: 15
  id: 14
}
connections {
  startIdx: 15
  endIdx: 16
  id: 15
}
connections {
  startIdx: 16
  endIdx: 17
  id: 16
}
connections {
  startIdx: 17
  endIdx: 18
  id: 17
}
connections {
  startIdx: 18
  endIdx: 19
  id: 18
}
connections {
  startIdx: 19
  endIdx: 20
  id: 19
}
connections {
  startIdx: 20
  endIdx: 21
  id: 20
}
connections {
  startIdx: 21
  endIdx: 22
  id: 21
}
connections {
  startIdx: 22
  endIdx: 23
  id: 22
}
connections {
  startIdx: 23
  endIdx: 24
  id: 23
}
connections {
  startIdx: 24
  endIdx: 25
  id: 24
}
connections {
  startIdx: 25
  endIdx: 26
  id: 25
}
connections {
  startIdx: 26
  endIdx: 27
  id: 26
}
connections {
  startIdx: 27
  endIdx: 28
  id: 27
}
connections {
  startIdx: 28
  endIdx: 29
  id: 28
}
connections {
  startIdx: 29
  endIdx: 30
  id: 29
}
connections {
  startIdx: 30
  endIdx: 31
  id: 30
}
connections {
  startIdx: 31
  endIdx: 32
  id: 31
}
connections {
  startIdx: 32
  endIdx: 33
  id: 32
}
connections {
  startIdx: 33
  endIdx: 34
  id: 33
}
connections {
  startIdx: 34
  endIdx: 35
  id: 34
}
connections {
  startIdx: 35
  endIdx: 36
  id: 35
}
connections {
  startIdx: 36
  endIdx: 37
  id: 36
}
connections {
  startIdx: 37
  endIdx: 38
  id: 37
}
connections {
  startIdx: 38
  endIdx: 39
  id: 38
}
connections {
  startIdx: 39
  endIdx: 40
  id: 39
}
connections {
  startIdx: 40
  endIdx: 41
  id: 40
}
connections {
  startIdx: 41
  endIdx: 42
  id: 41
}
connections {
  startIdx: 42
  endIdx: 43
  id: 42
}
connections {
  startIdx: 44
  endIdx: 45
  id: 43
}
connections {
  startIdx: 45
  endIdx: 46
  id: 44
}
connections {
  startIdx: 46
  endIdx: 47
  id: 45
}
connections {
  startIdx: 47
  endIdx: 48
  id: 46
}
connections {
  startIdx: 48
  endIdx: 49
  id: 47
}
connections {
  startIdx: 49
  endIdx: 50
  id: 48
}
connections {
  startIdx: 50
  endIdx: 51
  id: 49
}
connections {
  startIdx: 51
  endIdx: 52
  id: 50
}
connections {
  startIdx: 52
  endIdx: 53
  id: 51
}
connections {
  startIdx: 53
  endIdx: 54
  id: 52
}
connections {
  startIdx: 54
  endIdx: 55
  id: 53
}
connections {
  startIdx: 55
  endIdx: 56
  id: 54
}
connections {
  startIdx: 56
  endIdx: 57
  id: 55
}
connections {
  startIdx: 57
  endIdx: 58
  id: 56
}
connections {
  startIdx: 58
  endIdx: 59
  id: 57
}
connections {
  startIdx: 59
  endIdx: 60
  id: 58
}
connections {
  startIdx: 60
  endIdx: 61
  id: 59
}
connections {
  startIdx: 61
  endIdx: 62
  id: 60
}
connections {
  startIdx: 62
  endIdx: 63
  id: 61
}
connections {
  startIdx: 63
  endIdx: 64
  id: 62
}
connections {
  startIdx: 64
  endIdx: 65
  id: 63
}
connections {
  startIdx: 65
  endIdx: 66
  id: 64
}
connections {
  startIdx: 66
  endIdx: 67
  id: 65
}
connections {
  startIdx: 67
  endIdx: 68
  id: 66
}
connections {
  startIdx: 68
  endIdx: 69
  id: 67
}
connections {
  startIdx: 69
  endIdx: 70
  id: 68
}
connections {
  startIdx: 70
  endIdx: 71
  id: 69
}
connections {
  startIdx: 71
  endIdx: 72
  id: 70
}
connections {
  startIdx: 72
  endIdx: 73
  id: 71
}
connections {
  startIdx: 73
  endIdx: 74
  id: 72
}
connections {
  startIdx: 74
  endIdx: 75
  id: 73
}
connections {
  startIdx: 75
  endIdx: 76
  id: 74
}
connections {
  startIdx: 76
  endIdx: 77
  id: 75
}
connections {
  startIdx: 77
  endIdx: 78
  id: 76
}
connections {
  startIdx: 78
  endIdx: 79
  id: 77
}
connections {
  startIdx: 79
  endIdx: 80
  id: 78
}
connections {
  startIdx: 80
  endIdx: 81
  id: 79
}
connections {
  startIdx: 81
  endIdx: 82
  id: 80
}
connections {
  startIdx: 82
  endIdx: 83
  id: 81
}
connections {
  startIdx: 83
  endIdx: 84
  id: 82
}
connections {
  startIdx: 84
  endIdx: 85
  id: 83
}
connections {
  startIdx: 85
  endIdx: 86
  id: 84
}
connections {
  startIdx: 1
  endIdx: 128
  id: 85
}
connections {
  startIdx: 2
  endIdx: 127
  id: 86
}
connections {
  startIdx: 3
  endIdx: 126
  id: 87
}
connections {
  startIdx: 4
  endIdx: 125
  id: 88
}
connections {
  startIdx: 5
  endIdx: 124
  id: 89
}
connections {
  startIdx: 6
  endIdx: 123
  id: 90
}
connections {
  startIdx: 7
  endIdx: 122
  id: 91
}
connections {
  startIdx: 8
  endIdx: 121
  id: 92
}
connections {
  startIdx: 9
  endIdx: 120
  id: 93
}
connections {
  startIdx: 10
  endIdx: 119
  id: 94
}
connections {
  startIdx: 11
  endIdx: 118
  id: 95
}
connections {
  startIdx: 12
  endIdx: 117
  id: 96
}
connections {
  startIdx: 13
  endIdx: 116
  id: 97
}
connections {
  startIdx: 14
  endIdx: 115
  id: 98
}
connections {
  startIdx: 15
  endIdx: 114
  id: 99
}
connections {
  startIdx: 16
  endIdx: 113
  id: 100
}
connections {
  startIdx: 17
  endIdx: 112
  id: 101
}
connections {
  startIdx: 18
  endIdx: 111
  id: 102
}
connections {
  startIdx: 19
  endIdx: 110
  id: 103
}
connections {
  startIdx: 20
  endIdx: 109
  id: 104
}
connections {
  startIdx: 21
  endIdx: 108
  id: 105
}
connections {
  startIdx: 22
  endIdx: 107
  id: 106
}
connections {
  startIdx: 23
  endIdx: 106
  id: 107
}
connections {
  startIdx: 24
  endIdx: 105
  id: 108
}
connections {
  startIdx: 25
  endIdx: 104
  id: 109
}
connections {
  startIdx: 26
  endIdx: 103
  id: 110
}
connections {
  startIdx: 27
  endIdx: 102
  id: 111
}
connections {
  startIdx: 28
  endIdx: 101
  id: 112
}
connections {
  startIdx: 29
  endIdx: 100
  id: 113
}
connections {
  startIdx: 30
  endIdx: 99
  id: 114
}
connections {
  startIdx: 31
  endIdx: 98
  id: 115
}
connections {
  startIdx: 32
  endIdx: 97
  id: 116
}
connections {
  startIdx: 33
  endIdx: 96
  id: 117
}
connections {
  startIdx: 34
  endIdx: 95
  id: 118
}
connections {
  startIdx: 35
  endIdx: 94
  id: 119
}
connections {
  startIdx: 36
  endIdx: 93
  id: 120
}
connections {
  startIdx: 37
  endIdx: 92
  id: 121
}
connections {
  startIdx: 38
  endIdx: 91
  id: 122
}
connections {
  startIdx: 39
  endIdx: 90
  id: 123
}
connections {
  startIdx: 40
  endIdx: 89
  id: 124
}
connections {
  startIdx: 41
  endIdx: 88
  id: 125
}
connections {
  startIdx: 42
  endIdx: 87
  id: 126
}
connections {
  startIdx: 44
  endIdx: 88
  id: 127
}
connections {
  startIdx: 45
  endIdx: 89
  id: 128
}
connections {
  startIdx: 46
  endIdx: 90
  id: 129
}
connections {
  startIdx: 47
  endIdx: 91
  id: 130
}
connections {
  startIdx: 48
  endIdx: 92
  id: 131
}
connections {
  startIdx: 49
  endIdx: 93
  id: 132
}
connections {
  startIdx: 50
  endIdx: 94
  id: 133
}
connections {
  startIdx: 51
  endIdx: 95
  id: 134
}
connections {
  startIdx: 52
  endIdx: 96
  id: 135
}
connections {
  startIdx: 53
  endIdx: 97
  id: 136
}
connections {
  startIdx: 54
  endIdx: 98
  id: 137
}
connections {
  startIdx: 55
  endIdx: 99
  id: 138
}
connections {
  startIdx: 56
  endIdx: 100
  id: 139
}
connections {
  startIdx: 57
  endIdx: 101
  id: 140
}
connections {
  startIdx: 58
  endIdx: 102
  id: 141
}
connections {
  startIdx: 59
  endIdx: 103
  id: 142
}
connections {
  startIdx: 60
  endIdx: 104
  id: 143
}
connections {
  startIdx: 61
  endIdx: 105
  id: 144
}
connections {
  startIdx: 62
  endIdx: 106
  id: 145
}
connections {
  startIdx: 63
  endIdx: 107
  id: 146
}
connections {
  startIdx: 64
  endIdx: 108
  id: 147
}
connections {
  startIdx: 65
  endIdx: 109
  id: 148
}
connections {
  startIdx: 66
  endIdx: 110
  id: 149
}
connections {
  startIdx: 67
  endIdx: 111
  id: 150
}
connections {
  startIdx: 68
  endIdx: 112
  id: 151
}
connections {
  startIdx: 69
  endIdx: 113
  id: 152
}
connections {
  startIdx: 70
  endIdx: 114
  id: 153
}
connections {
  startIdx: 71
  endIdx: 115
  id: 154
}
connections {
  startIdx: 72
  endIdx: 116
  id: 155
}
connections {
  startIdx: 73
  endIdx: 117
  id: 156
}
connections {
  startIdx: 74
  endIdx: 118
  id: 157
}
connections {
  startIdx: 75
  endIdx: 119
  id: 158
}
connections {
  startIdx: 76
  endIdx: 120
  id: 159
}
connections {
  startIdx: 77
  endIdx: 121
  id: 160
}
connections {
  startIdx: 78
  endIdx: 122
  id: 161
}
connections {
  startIdx: 79
  endIdx: 123
  id: 162
}
connections {
  startIdx: 80
  endIdx: 124
  id: 163
}
connections {
  startIdx: 81
  endIdx: 125
  id: 164
}
connections {
  startIdx: 82
  endIdx: 126
  id: 165
}
connections {
  startIdx: 83
  endIdx: 127
  id: 166
}
connections {
  startIdx: 84
  endIdx: 128
  id: 167
}
connections {
  startIdx: 85
  endIdx: 129
  id: 168
}

}
system {
	num_chip: 128
	accelerator {
		core: 432
		systolic_width: 16
		systolic_height: 16
		sram_cap: 88080384.0
		freq: 1.41
	}
	r_fc {
		x: 8
		y: 16
		link_bw_x: 600.0
		link_bw_y: 25.0
	}
	memory {
		dram_bw: 1555.0
		dram_cap: 42949672960.0
	}
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 19999.99997
  
  dram_unit_power: 0.16248
  link_unit_power_x: 0.0104
  link_unit_power_y: 0.052
  accelerator_power: 511.5771047
}
miscellany {
	dlrm {
		num_table: 50
		emb_dim: 92
		row: 72173913
		global_batch_size: 128000000
	}
	execution_style: KERNEL_BY_KERNEL
	perfect_overlap: false
	compute_util: 0.9
	word: 2
}
gurobi {
  thread: 144
  gap: 0.001
  time: 3600
}
