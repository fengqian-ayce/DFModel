dataflow_graph {
  kernels {
    name: "MLP_1"
    id: 1
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_2"
    id: 2
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_3"
    id: 3
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_4"
    id: 4
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_5"
    id: 5
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_6"
    id: 6
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_7"
    id: 7
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_8"
    id: 8
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_9"
    id: 9
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_10"
    id: 10
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_11"
    id: 11
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_12"
    id: 12
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_13"
    id: 13
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      communication_type: ALL_TO_ALL
      communication_size: 10304000.0
      tiling: NO_TILING
      memory_size: 1318912000.0
    }
  }
  kernels {
    name: "MLP_14"
    id: 14
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_15"
    id: 15
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_16"
    id: 16
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_17"
    id: 17
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_18"
    id: 18
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_19"
    id: 19
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_20"
    id: 20
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_21"
    id: 21
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_22"
    id: 22
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_23"
    id: 23
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_24"
    id: 24
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_25"
    id: 25
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_26"
    id: 26
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_27"
    id: 27
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_28"
    id: 28
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_29"
    id: 29
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_30"
    id: 30
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_31"
    id: 31
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_32"
    id: 32
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_33"
    id: 33
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_34"
    id: 34
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_35"
    id: 35
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_36"
    id: 36
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_37"
    id: 37
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_38"
    id: 38
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_39"
    id: 39
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_40"
    id: 40
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_41"
    id: 41
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_42"
    id: 42
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_43"
    id: 43
    config: -1
    fwd_bwd: FWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_43_bwd"
    id: 44
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_42_bwd"
    id: 45
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_41_bwd"
    id: 46
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_40_bwd"
    id: 47
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_39_bwd"
    id: 48
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_38_bwd"
    id: 49
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_37_bwd"
    id: 50
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_36_bwd"
    id: 51
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_35_bwd"
    id: 52
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_34_bwd"
    id: 53
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_33_bwd"
    id: 54
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_32_bwd"
    id: 55
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_31_bwd"
    id: 56
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_30_bwd"
    id: 57
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_29_bwd"
    id: 58
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_28_bwd"
    id: 59
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_27_bwd"
    id: 60
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_26_bwd"
    id: 61
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_25_bwd"
    id: 62
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_24_bwd"
    id: 63
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_23_bwd"
    id: 64
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_22_bwd"
    id: 65
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_21_bwd"
    id: 66
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_20_bwd"
    id: 67
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_19_bwd"
    id: 68
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_18_bwd"
    id: 69
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_17_bwd"
    id: 70
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_16_bwd"
    id: 71
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_15_bwd"
    id: 72
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_14_bwd"
    id: 73
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_13_bwd"
    id: 74
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      communication_type: ALL_TO_ALL
      communication_size: 10304000.0
      tiling: NO_TILING
      memory_size: 1318912000.0
    }
  }
  kernels {
    name: "MLP_12_bwd"
    id: 75
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_11_bwd"
    id: 76
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_10_bwd"
    id: 77
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_9_bwd"
    id: 78
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_8_bwd"
    id: 79
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_7_bwd"
    id: 80
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_6_bwd"
    id: 81
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_5_bwd"
    id: 82
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_4_bwd"
    id: 83
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_3_bwd"
    id: 84
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_2_bwd"
    id: 85
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_1_bwd"
    id: 86
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_weight {
      outer: 1
      M: 682
      K: 682
      N: 2048
      input_tensor_size: 2793472.0
      weight_tensor_size: 930248.0
      output_tensor_size: 2793472.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_43_bwd_weight_update"
    id: 87
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_42_bwd_weight_update"
    id: 88
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_41_bwd_weight_update"
    id: 89
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_40_bwd_weight_update"
    id: 90
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_39_bwd_weight_update"
    id: 91
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_38_bwd_weight_update"
    id: 92
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_37_bwd_weight_update"
    id: 93
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_36_bwd_weight_update"
    id: 94
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_35_bwd_weight_update"
    id: 95
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_34_bwd_weight_update"
    id: 96
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_33_bwd_weight_update"
    id: 97
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_32_bwd_weight_update"
    id: 98
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_31_bwd_weight_update"
    id: 99
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_30_bwd_weight_update"
    id: 100
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_29_bwd_weight_update"
    id: 101
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_28_bwd_weight_update"
    id: 102
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_27_bwd_weight_update"
    id: 103
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_26_bwd_weight_update"
    id: 104
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_25_bwd_weight_update"
    id: 105
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_24_bwd_weight_update"
    id: 106
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_23_bwd_weight_update"
    id: 107
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_22_bwd_weight_update"
    id: 108
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_21_bwd_weight_update"
    id: 109
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_20_bwd_weight_update"
    id: 110
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_19_bwd_weight_update"
    id: 111
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_18_bwd_weight_update"
    id: 112
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_17_bwd_weight_update"
    id: 113
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_16_bwd_weight_update"
    id: 114
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_15_bwd_weight_update"
    id: 115
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_14_bwd_weight_update"
    id: 116
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_13_bwd_weight_update"
    id: 117
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_12_bwd_weight_update"
    id: 118
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_11_bwd_weight_update"
    id: 119
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_10_bwd_weight_update"
    id: 120
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_9_bwd_weight_update"
    id: 121
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_8_bwd_weight_update"
    id: 122
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_7_bwd_weight_update"
    id: 123
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_6_bwd_weight_update"
    id: 124
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_5_bwd_weight_update"
    id: 125
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_4_bwd_weight_update"
    id: 126
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_3_bwd_weight_update"
    id: 127
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_2_bwd_weight_update"
    id: 128
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  kernels {
    name: "MLP_1_bwd_weight_update"
    id: 129
    config: -1
    fwd_bwd: BWD
    type: SYSTOLIC
    gemm_input1_input2 {
      outer: 1
      M: 682
      K: 2048
      N: 682
      input_tensor_1_size: 2793472.0
      input_tensor_2_size: 2793472.0
      output_tensor_size: 930248.0
      communication_type: ALL_REDUCE_PERIODIC
      communication_size: 930248.0
      tiling: NO_TILING
    }
  }
  connections {
    startIdx: 1
    endIdx: 2
    id: 1
    lane_stage_type: LANE
  }
  connections {
    startIdx: 2
    endIdx: 3
    id: 2
    lane_stage_type: LANE
  }
  connections {
    startIdx: 3
    endIdx: 4
    id: 3
    lane_stage_type: LANE
  }
  connections {
    startIdx: 4
    endIdx: 5
    id: 4
    lane_stage_type: LANE
  }
  connections {
    startIdx: 5
    endIdx: 6
    id: 5
    lane_stage_type: LANE
  }
  connections {
    startIdx: 6
    endIdx: 7
    id: 6
    lane_stage_type: LANE
  }
  connections {
    startIdx: 7
    endIdx: 8
    id: 7
    lane_stage_type: LANE
  }
  connections {
    startIdx: 8
    endIdx: 9
    id: 8
    lane_stage_type: LANE
  }
  connections {
    startIdx: 9
    endIdx: 10
    id: 9
    lane_stage_type: LANE
  }
  connections {
    startIdx: 10
    endIdx: 11
    id: 10
    lane_stage_type: LANE
  }
  connections {
    startIdx: 11
    endIdx: 12
    id: 11
    lane_stage_type: LANE
  }
  connections {
    startIdx: 12
    endIdx: 13
    id: 12
    lane_stage_type: LANE
  }
  connections {
    startIdx: 13
    endIdx: 14
    id: 13
    lane_stage_type: LANE
  }
  connections {
    startIdx: 14
    endIdx: 15
    id: 14
    lane_stage_type: LANE
  }
  connections {
    startIdx: 15
    endIdx: 16
    id: 15
    lane_stage_type: LANE
  }
  connections {
    startIdx: 16
    endIdx: 17
    id: 16
    lane_stage_type: LANE
  }
  connections {
    startIdx: 17
    endIdx: 18
    id: 17
    lane_stage_type: LANE
  }
  connections {
    startIdx: 18
    endIdx: 19
    id: 18
    lane_stage_type: LANE
  }
  connections {
    startIdx: 19
    endIdx: 20
    id: 19
    lane_stage_type: LANE
  }
  connections {
    startIdx: 20
    endIdx: 21
    id: 20
    lane_stage_type: LANE
  }
  connections {
    startIdx: 21
    endIdx: 22
    id: 21
    lane_stage_type: LANE
  }
  connections {
    startIdx: 22
    endIdx: 23
    id: 22
    lane_stage_type: LANE
  }
  connections {
    startIdx: 23
    endIdx: 24
    id: 23
    lane_stage_type: LANE
  }
  connections {
    startIdx: 24
    endIdx: 25
    id: 24
    lane_stage_type: LANE
  }
  connections {
    startIdx: 25
    endIdx: 26
    id: 25
    lane_stage_type: LANE
  }
  connections {
    startIdx: 26
    endIdx: 27
    id: 26
    lane_stage_type: LANE
  }
  connections {
    startIdx: 27
    endIdx: 28
    id: 27
    lane_stage_type: LANE
  }
  connections {
    startIdx: 28
    endIdx: 29
    id: 28
    lane_stage_type: LANE
  }
  connections {
    startIdx: 29
    endIdx: 30
    id: 29
    lane_stage_type: LANE
  }
  connections {
    startIdx: 30
    endIdx: 31
    id: 30
    lane_stage_type: LANE
  }
  connections {
    startIdx: 31
    endIdx: 32
    id: 31
    lane_stage_type: LANE
  }
  connections {
    startIdx: 32
    endIdx: 33
    id: 32
    lane_stage_type: LANE
  }
  connections {
    startIdx: 33
    endIdx: 34
    id: 33
    lane_stage_type: LANE
  }
  connections {
    startIdx: 34
    endIdx: 35
    id: 34
    lane_stage_type: LANE
  }
  connections {
    startIdx: 35
    endIdx: 36
    id: 35
    lane_stage_type: LANE
  }
  connections {
    startIdx: 36
    endIdx: 37
    id: 36
    lane_stage_type: LANE
  }
  connections {
    startIdx: 37
    endIdx: 38
    id: 37
    lane_stage_type: LANE
  }
  connections {
    startIdx: 38
    endIdx: 39
    id: 38
    lane_stage_type: LANE
  }
  connections {
    startIdx: 39
    endIdx: 40
    id: 39
    lane_stage_type: LANE
  }
  connections {
    startIdx: 40
    endIdx: 41
    id: 40
    lane_stage_type: LANE
  }
  connections {
    startIdx: 41
    endIdx: 42
    id: 41
    lane_stage_type: LANE
  }
  connections {
    startIdx: 42
    endIdx: 43
    id: 42
    lane_stage_type: LANE
  }
  connections {
    startIdx: 44
    endIdx: 45
    id: 43
    lane_stage_type: LANE
  }
  connections {
    startIdx: 45
    endIdx: 46
    id: 44
    lane_stage_type: LANE
  }
  connections {
    startIdx: 46
    endIdx: 47
    id: 45
    lane_stage_type: LANE
  }
  connections {
    startIdx: 47
    endIdx: 48
    id: 46
    lane_stage_type: LANE
  }
  connections {
    startIdx: 48
    endIdx: 49
    id: 47
    lane_stage_type: LANE
  }
  connections {
    startIdx: 49
    endIdx: 50
    id: 48
    lane_stage_type: LANE
  }
  connections {
    startIdx: 50
    endIdx: 51
    id: 49
    lane_stage_type: LANE
  }
  connections {
    startIdx: 51
    endIdx: 52
    id: 50
    lane_stage_type: LANE
  }
  connections {
    startIdx: 52
    endIdx: 53
    id: 51
    lane_stage_type: LANE
  }
  connections {
    startIdx: 53
    endIdx: 54
    id: 52
    lane_stage_type: LANE
  }
  connections {
    startIdx: 54
    endIdx: 55
    id: 53
    lane_stage_type: LANE
  }
  connections {
    startIdx: 55
    endIdx: 56
    id: 54
    lane_stage_type: LANE
  }
  connections {
    startIdx: 56
    endIdx: 57
    id: 55
    lane_stage_type: LANE
  }
  connections {
    startIdx: 57
    endIdx: 58
    id: 56
    lane_stage_type: LANE
  }
  connections {
    startIdx: 58
    endIdx: 59
    id: 57
    lane_stage_type: LANE
  }
  connections {
    startIdx: 59
    endIdx: 60
    id: 58
    lane_stage_type: LANE
  }
  connections {
    startIdx: 60
    endIdx: 61
    id: 59
    lane_stage_type: LANE
  }
  connections {
    startIdx: 61
    endIdx: 62
    id: 60
    lane_stage_type: LANE
  }
  connections {
    startIdx: 62
    endIdx: 63
    id: 61
    lane_stage_type: LANE
  }
  connections {
    startIdx: 63
    endIdx: 64
    id: 62
    lane_stage_type: LANE
  }
  connections {
    startIdx: 64
    endIdx: 65
    id: 63
    lane_stage_type: LANE
  }
  connections {
    startIdx: 65
    endIdx: 66
    id: 64
    lane_stage_type: LANE
  }
  connections {
    startIdx: 66
    endIdx: 67
    id: 65
    lane_stage_type: LANE
  }
  connections {
    startIdx: 67
    endIdx: 68
    id: 66
    lane_stage_type: LANE
  }
  connections {
    startIdx: 68
    endIdx: 69
    id: 67
    lane_stage_type: LANE
  }
  connections {
    startIdx: 69
    endIdx: 70
    id: 68
    lane_stage_type: LANE
  }
  connections {
    startIdx: 70
    endIdx: 71
    id: 69
    lane_stage_type: LANE
  }
  connections {
    startIdx: 71
    endIdx: 72
    id: 70
    lane_stage_type: LANE
  }
  connections {
    startIdx: 72
    endIdx: 73
    id: 71
    lane_stage_type: LANE
  }
  connections {
    startIdx: 73
    endIdx: 74
    id: 72
    lane_stage_type: LANE
  }
  connections {
    startIdx: 74
    endIdx: 75
    id: 73
    lane_stage_type: LANE
  }
  connections {
    startIdx: 75
    endIdx: 76
    id: 74
    lane_stage_type: LANE
  }
  connections {
    startIdx: 76
    endIdx: 77
    id: 75
    lane_stage_type: LANE
  }
  connections {
    startIdx: 77
    endIdx: 78
    id: 76
    lane_stage_type: LANE
  }
  connections {
    startIdx: 78
    endIdx: 79
    id: 77
    lane_stage_type: LANE
  }
  connections {
    startIdx: 79
    endIdx: 80
    id: 78
    lane_stage_type: LANE
  }
  connections {
    startIdx: 80
    endIdx: 81
    id: 79
    lane_stage_type: LANE
  }
  connections {
    startIdx: 81
    endIdx: 82
    id: 80
    lane_stage_type: LANE
  }
  connections {
    startIdx: 82
    endIdx: 83
    id: 81
    lane_stage_type: LANE
  }
  connections {
    startIdx: 83
    endIdx: 84
    id: 82
    lane_stage_type: LANE
  }
  connections {
    startIdx: 84
    endIdx: 85
    id: 83
    lane_stage_type: LANE
  }
  connections {
    startIdx: 85
    endIdx: 86
    id: 84
    lane_stage_type: LANE
  }
  connections {
    startIdx: 1
    endIdx: 128
    id: 85
    lane_stage_type: LANE
  }
  connections {
    startIdx: 2
    endIdx: 127
    id: 86
    lane_stage_type: LANE
  }
  connections {
    startIdx: 3
    endIdx: 126
    id: 87
    lane_stage_type: LANE
  }
  connections {
    startIdx: 4
    endIdx: 125
    id: 88
    lane_stage_type: LANE
  }
  connections {
    startIdx: 5
    endIdx: 124
    id: 89
    lane_stage_type: LANE
  }
  connections {
    startIdx: 6
    endIdx: 123
    id: 90
    lane_stage_type: LANE
  }
  connections {
    startIdx: 7
    endIdx: 122
    id: 91
    lane_stage_type: LANE
  }
  connections {
    startIdx: 8
    endIdx: 121
    id: 92
    lane_stage_type: LANE
  }
  connections {
    startIdx: 9
    endIdx: 120
    id: 93
    lane_stage_type: LANE
  }
  connections {
    startIdx: 10
    endIdx: 119
    id: 94
    lane_stage_type: LANE
  }
  connections {
    startIdx: 11
    endIdx: 118
    id: 95
    lane_stage_type: LANE
  }
  connections {
    startIdx: 12
    endIdx: 117
    id: 96
    lane_stage_type: LANE
  }
  connections {
    startIdx: 13
    endIdx: 116
    id: 97
    lane_stage_type: LANE
  }
  connections {
    startIdx: 14
    endIdx: 115
    id: 98
    lane_stage_type: LANE
  }
  connections {
    startIdx: 15
    endIdx: 114
    id: 99
    lane_stage_type: LANE
  }
  connections {
    startIdx: 16
    endIdx: 113
    id: 100
    lane_stage_type: LANE
  }
  connections {
    startIdx: 17
    endIdx: 112
    id: 101
    lane_stage_type: LANE
  }
  connections {
    startIdx: 18
    endIdx: 111
    id: 102
    lane_stage_type: LANE
  }
  connections {
    startIdx: 19
    endIdx: 110
    id: 103
    lane_stage_type: LANE
  }
  connections {
    startIdx: 20
    endIdx: 109
    id: 104
    lane_stage_type: LANE
  }
  connections {
    startIdx: 21
    endIdx: 108
    id: 105
    lane_stage_type: LANE
  }
  connections {
    startIdx: 22
    endIdx: 107
    id: 106
    lane_stage_type: LANE
  }
  connections {
    startIdx: 23
    endIdx: 106
    id: 107
    lane_stage_type: LANE
  }
  connections {
    startIdx: 24
    endIdx: 105
    id: 108
    lane_stage_type: LANE
  }
  connections {
    startIdx: 25
    endIdx: 104
    id: 109
    lane_stage_type: LANE
  }
  connections {
    startIdx: 26
    endIdx: 103
    id: 110
    lane_stage_type: LANE
  }
  connections {
    startIdx: 27
    endIdx: 102
    id: 111
    lane_stage_type: LANE
  }
  connections {
    startIdx: 28
    endIdx: 101
    id: 112
    lane_stage_type: LANE
  }
  connections {
    startIdx: 29
    endIdx: 100
    id: 113
    lane_stage_type: LANE
  }
  connections {
    startIdx: 30
    endIdx: 99
    id: 114
    lane_stage_type: LANE
  }
  connections {
    startIdx: 31
    endIdx: 98
    id: 115
    lane_stage_type: LANE
  }
  connections {
    startIdx: 32
    endIdx: 97
    id: 116
    lane_stage_type: LANE
  }
  connections {
    startIdx: 33
    endIdx: 96
    id: 117
    lane_stage_type: LANE
  }
  connections {
    startIdx: 34
    endIdx: 95
    id: 118
    lane_stage_type: LANE
  }
  connections {
    startIdx: 35
    endIdx: 94
    id: 119
    lane_stage_type: LANE
  }
  connections {
    startIdx: 36
    endIdx: 93
    id: 120
    lane_stage_type: LANE
  }
  connections {
    startIdx: 37
    endIdx: 92
    id: 121
    lane_stage_type: LANE
  }
  connections {
    startIdx: 38
    endIdx: 91
    id: 122
    lane_stage_type: LANE
  }
  connections {
    startIdx: 39
    endIdx: 90
    id: 123
    lane_stage_type: LANE
  }
  connections {
    startIdx: 40
    endIdx: 89
    id: 124
    lane_stage_type: LANE
  }
  connections {
    startIdx: 41
    endIdx: 88
    id: 125
    lane_stage_type: LANE
  }
  connections {
    startIdx: 42
    endIdx: 87
    id: 126
    lane_stage_type: LANE
  }
  connections {
    startIdx: 44
    endIdx: 88
    id: 127
    lane_stage_type: LANE
  }
  connections {
    startIdx: 45
    endIdx: 89
    id: 128
    lane_stage_type: LANE
  }
  connections {
    startIdx: 46
    endIdx: 90
    id: 129
    lane_stage_type: LANE
  }
  connections {
    startIdx: 47
    endIdx: 91
    id: 130
    lane_stage_type: LANE
  }
  connections {
    startIdx: 48
    endIdx: 92
    id: 131
    lane_stage_type: LANE
  }
  connections {
    startIdx: 49
    endIdx: 93
    id: 132
    lane_stage_type: LANE
  }
  connections {
    startIdx: 50
    endIdx: 94
    id: 133
    lane_stage_type: LANE
  }
  connections {
    startIdx: 51
    endIdx: 95
    id: 134
    lane_stage_type: LANE
  }
  connections {
    startIdx: 52
    endIdx: 96
    id: 135
    lane_stage_type: LANE
  }
  connections {
    startIdx: 53
    endIdx: 97
    id: 136
    lane_stage_type: LANE
  }
  connections {
    startIdx: 54
    endIdx: 98
    id: 137
    lane_stage_type: LANE
  }
  connections {
    startIdx: 55
    endIdx: 99
    id: 138
    lane_stage_type: LANE
  }
  connections {
    startIdx: 56
    endIdx: 100
    id: 139
    lane_stage_type: LANE
  }
  connections {
    startIdx: 57
    endIdx: 101
    id: 140
    lane_stage_type: LANE
  }
  connections {
    startIdx: 58
    endIdx: 102
    id: 141
    lane_stage_type: LANE
  }
  connections {
    startIdx: 59
    endIdx: 103
    id: 142
    lane_stage_type: LANE
  }
  connections {
    startIdx: 60
    endIdx: 104
    id: 143
    lane_stage_type: LANE
  }
  connections {
    startIdx: 61
    endIdx: 105
    id: 144
    lane_stage_type: LANE
  }
  connections {
    startIdx: 62
    endIdx: 106
    id: 145
    lane_stage_type: LANE
  }
  connections {
    startIdx: 63
    endIdx: 107
    id: 146
    lane_stage_type: LANE
  }
  connections {
    startIdx: 64
    endIdx: 108
    id: 147
    lane_stage_type: LANE
  }
  connections {
    startIdx: 65
    endIdx: 109
    id: 148
    lane_stage_type: LANE
  }
  connections {
    startIdx: 66
    endIdx: 110
    id: 149
    lane_stage_type: LANE
  }
  connections {
    startIdx: 67
    endIdx: 111
    id: 150
    lane_stage_type: LANE
  }
  connections {
    startIdx: 68
    endIdx: 112
    id: 151
    lane_stage_type: LANE
  }
  connections {
    startIdx: 69
    endIdx: 113
    id: 152
    lane_stage_type: LANE
  }
  connections {
    startIdx: 70
    endIdx: 114
    id: 153
    lane_stage_type: LANE
  }
  connections {
    startIdx: 71
    endIdx: 115
    id: 154
    lane_stage_type: LANE
  }
  connections {
    startIdx: 72
    endIdx: 116
    id: 155
    lane_stage_type: LANE
  }
  connections {
    startIdx: 73
    endIdx: 117
    id: 156
    lane_stage_type: LANE
  }
  connections {
    startIdx: 74
    endIdx: 118
    id: 157
    lane_stage_type: LANE
  }
  connections {
    startIdx: 75
    endIdx: 119
    id: 158
    lane_stage_type: LANE
  }
  connections {
    startIdx: 76
    endIdx: 120
    id: 159
    lane_stage_type: LANE
  }
  connections {
    startIdx: 77
    endIdx: 121
    id: 160
    lane_stage_type: LANE
  }
  connections {
    startIdx: 78
    endIdx: 122
    id: 161
    lane_stage_type: LANE
  }
  connections {
    startIdx: 79
    endIdx: 123
    id: 162
    lane_stage_type: LANE
  }
  connections {
    startIdx: 80
    endIdx: 124
    id: 163
    lane_stage_type: LANE
  }
  connections {
    startIdx: 81
    endIdx: 125
    id: 164
    lane_stage_type: LANE
  }
  connections {
    startIdx: 82
    endIdx: 126
    id: 165
    lane_stage_type: LANE
  }
  connections {
    startIdx: 83
    endIdx: 127
    id: 166
    lane_stage_type: LANE
  }
  connections {
    startIdx: 84
    endIdx: 128
    id: 167
    lane_stage_type: LANE
  }
  connections {
    startIdx: 85
    endIdx: 129
    id: 168
    lane_stage_type: LANE
  }
}
system {
  num_chip: 128
  accelerator {
    core: 432
    systolic_width: 16
    systolic_height: 16
    sram_cap: 88080380.0
    freq: 1.41
  }
  r_fc {
    x: 8
    y: 16
    link_bw_x: 600.0
    link_bw_y: 25.0
  }
  memory {
    dram_bw: 1555.0
    dram_cap: 42949673000.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 20000.0
  link_unit_power_x: 0.0104
  link_unit_power_y: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 511.57712
}
execution {
  dlrm {
    num_table: 50
    emb_dim: 92
    row: 72173913
    global_batch_size: 128000000
    num_copy: 1
  }
  execution_style: KERNEL_BY_KERNEL
  overlap: PERFECT_OVERLAP
  word: 2
}
gurobi {
  gap: 0.001
  time: 180
}
