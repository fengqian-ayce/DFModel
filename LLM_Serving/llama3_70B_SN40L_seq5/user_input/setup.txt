dataflow_graph {
kernels {
  name: "Add_Prev_Layer"
  id: 1
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "LayerNorm_1"
  id: 2
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "Q"
  id: 3
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 64
    M: 128
    K: 8192
    N: 5
    input_tensor_size: 81920.0
    weight_tensor_size: 134217730.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    memory_size: 8388608.0
  }
}
kernels {
  name: "K"
  id: 4
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 64
    M: 128
    K: 8192
    N: 5
    input_tensor_size: 81920.0
    weight_tensor_size: 134217730.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    memory_size: 8388608.0
  }
}
kernels {
  name: "V"
  id: 5
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 64
    M: 128
    K: 8192
    N: 5
    input_tensor_size: 81920.0
    weight_tensor_size: 134217730.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    memory_size: 8388608.0
  }
}
kernels {
  name: "K_cache"
  id: 6
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  elementwise_input1 {
    outer: 64
    M: 128
    N: 4096
    input_tensor_size: 81920.0
    output_tensor_size: 67108864.0
    tiling: N_TILING
    memory_size: 4194304.0
    sram_extra: 4194304.0
    dram_extra: 4194304.0
  }
}
kernels {
  name: "V_cache"
  id: 7
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  elementwise_input1 {
    outer: 64
    M: 128
    N: 4096
    input_tensor_size: 81920.0
    output_tensor_size: 67108864.0
    tiling: N_TILING
    memory_size: 4194304.0
    sram_extra: 4194304.0
    dram_extra: 4194304.0
  }
}
kernels {
  name: "MHA_GEMM_1"
  id: 8
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 64
    M: 5
    K: 128
    N: 4096
    input_tensor_1_size: 81920.0
    input_tensor_2_size: 67108864.0
    output_tensor_size: 2621440.0
    tiling: N_TILING
  }
}
kernels {
  name: "SOFTMAX"
  id: 9
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 64
    M: 5
    N: 4096
    input_tensor_size: 2621440.0
    output_tensor_size: 2621440.0
    tiling: N_TILING
  }
}
kernels {
  name: "DropOut_1"
  id: 10
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 64
    M: 5
    N: 4096
    input_tensor_size: 2621440.0
    output_tensor_size: 2621440.0
    tiling: N_TILING
  }
}
kernels {
  name: "MHA_GEMM_2"
  id: 11
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 64
    M: 128
    K: 4096
    N: 5
    input_tensor_1_size: 67108864.0
    input_tensor_2_size: 2621440.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "PROJ_GEMM"
  id: 12
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 8192
    K: 8192
    N: 5
    input_tensor_size: 81920.0
    weight_tensor_size: 134217730.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    memory_size: 8388608.0
  }
}
kernels {
  name: "DropOut_2"
  id: 13
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "Add_1"
  id: 14
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1_input2 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_1_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    input_tensor_2_size: 81920.0
  }
}
kernels {
  name: "LayerNorm_2"
  id: 15
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "FFN0"
  id: 16
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 28672
    K: 8192
    N: 5
    input_tensor_size: 81920.0
    weight_tensor_size: 469762050.0
    output_tensor_size: 286720.0
    tiling: N_TILING
    memory_size: 29360128.0
  }
}
kernels {
  name: "GeLU"
  id: 17
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 28672
    N: 5
    input_tensor_size: 286720.0
    output_tensor_size: 286720.0
    tiling: N_TILING
  }
}
kernels {
  name: "FFN1"
  id: 18
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 8192
    K: 28672
    N: 5
    input_tensor_size: 286720.0
    weight_tensor_size: 469762050.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    memory_size: 29360128.0
  }
}
kernels {
  name: "DropOut_3"
  id: 19
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
  }
}
kernels {
  name: "Add_2"
  id: 20
  config: -1
  fwd_bwd: FWD
  type: SIMD
  elementwise_input1_input2 {
    outer: 1
    M: 8192
    N: 5
    input_tensor_1_size: 81920.0
    output_tensor_size: 81920.0
    tiling: N_TILING
    input_tensor_2_size: 81920.0
  }
}
connections {
  startIdx: 1
  endIdx: 2
  id: 1
}
connections {
  startIdx: 2
  endIdx: 3
  id: 2
}
connections {
  startIdx: 2
  endIdx: 4
  id: 3
}
connections {
  startIdx: 2
  endIdx: 5
  id: 4
}
connections {
  startIdx: 4
  endIdx: 6
  id: 5
}
connections {
  startIdx: 5
  endIdx: 7
  id: 6
}
connections {
  startIdx: 3
  endIdx: 8
  id: 7
}
connections {
  startIdx: 6
  endIdx: 8
  id: 8
  zero_out: true
}
connections {
  startIdx: 8
  endIdx: 9
  id: 9
}
connections {
  startIdx: 9
  endIdx: 10
  id: 10
}
connections {
  startIdx: 10
  endIdx: 11
  id: 11
}
connections {
  startIdx: 7
  endIdx: 11
  id: 12
  zero_out: true
}
connections {
  startIdx: 11
  endIdx: 12
  id: 13
}
connections {
  startIdx: 12
  endIdx: 13
  id: 14
}
connections {
  startIdx: 13
  endIdx: 14
  id: 15
}
connections {
  startIdx: 14
  endIdx: 15
  id: 16
}
connections {
  startIdx: 1
  endIdx: 14
  id: 17
}
connections {
  startIdx: 15
  endIdx: 16
  id: 18
}
connections {
  startIdx: 16
  endIdx: 17
  id: 19
}
connections {
  startIdx: 17
  endIdx: 18
  id: 20
}
connections {
  startIdx: 18
  endIdx: 19
  id: 21
}
connections {
  startIdx: 19
  endIdx: 20
  id: 22
}
connections {
  startIdx: 14
  endIdx: 20
  id: 23
}
}
system {
  num_chip: 16
  accelerator {
    core: 1040
    systolic_width: 32
    systolic_height: 6
    sram_cap: 545259520.0
    freq: 1.6

    link_latency: 150
  }
  r {
    x: 16
    link_bw_x: 50.0
    par_x: "TP"
  }
  memory {
    dram_bw: 1638.4
    dram_cap: 68719476736.0
  }
}
cost {
  link_unit_price: 2.0
  switch_unit_price: 24.0
  dram_unit_price: 1.0
  accelerator_price: 33000
  link_unit_power_x: 0.0104
  switch_unit_power: 0.052
  dram_unit_power: 0.16248
  accelerator_power: 750
}
execution {
  llm {
    hidden_dim: 8192
    head_dim: 128
    num_head: 64
    seq_len: 5
    num_layer: 80
	  global_batch_size: 16384
	  micro_batch_size: 1
    num_layer_in_graph: 1
  }
  execution_style: DATAFLOW
  num_config: 1
  overlap: NO_OVERLAP
  separate_rs_ag_for_ar: true
  compute_util: 0.9
  word: 2
}
gurobi {
  gap: 0.001
  time: 180
}