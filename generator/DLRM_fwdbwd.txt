kernels {
  name: "MLP_1"
  id: 1
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2"
  id: 2
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_3"
  id: 3
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4"
  id: 4
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    communication_type: ALL_TO_ALL
    communication_size: 2560.0
    tiling: NO_TILING
    memory_size: 2560.0
  }
}
kernels {
  name: "MLP_5"
  id: 5
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6"
  id: 6
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7"
  id: 7
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8"
  id: 8
  config: -1
  fwd_bwd: FWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8_bwd"
  id: 9
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7_bwd"
  id: 10
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6_bwd"
  id: 11
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_5_bwd"
  id: 12
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4_bwd"
  id: 13
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    communication_type: ALL_TO_ALL
    communication_size: 2560.0
    tiling: NO_TILING
    memory_size: 2560.0
  }
}
kernels {
  name: "MLP_3_bwd"
  id: 14
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2_bwd"
  id: 15
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_1_bwd"
  id: 16
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_weight {
    outer: 1
    M: 1000
    K: 1000
    N: 16
    input_tensor_size: 32000.0
    weight_tensor_size: 2000000.0
    output_tensor_size: 32000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_8_bwd_weight_update"
  id: 17
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_7_bwd_weight_update"
  id: 18
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_6_bwd_weight_update"
  id: 19
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_5_bwd_weight_update"
  id: 20
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_4_bwd_weight_update"
  id: 21
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_3_bwd_weight_update"
  id: 22
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_2_bwd_weight_update"
  id: 23
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
kernels {
  name: "MLP_1_bwd_weight_update"
  id: 24
  config: -1
  fwd_bwd: BWD
  type: SYSTOLIC
  gemm_input1_input2 {
    outer: 1
    M: 1000
    K: 16
    N: 1000
    input_tensor_1_size: 32000.0
    input_tensor_2_size: 32000.0
    output_tensor_size: 2000000.0
    communication_type: ALL_REDUCE_PERIODIC
    communication_size: 2000000.0
    tiling: NO_TILING
  }
}
connections {
  startIdx: 1
  endIdx: 2
  id: 1
}
connections {
  startIdx: 2
  endIdx: 3
  id: 2
}
connections {
  startIdx: 3
  endIdx: 4
  id: 3
}
connections {
  startIdx: 4
  endIdx: 5
  id: 4
}
connections {
  startIdx: 5
  endIdx: 6
  id: 5
}
connections {
  startIdx: 6
  endIdx: 7
  id: 6
}
connections {
  startIdx: 7
  endIdx: 8
  id: 7
}
connections {
  startIdx: 9
  endIdx: 10
  id: 8
}
connections {
  startIdx: 10
  endIdx: 11
  id: 9
}
connections {
  startIdx: 11
  endIdx: 12
  id: 10
}
connections {
  startIdx: 12
  endIdx: 13
  id: 11
}
connections {
  startIdx: 13
  endIdx: 14
  id: 12
}
connections {
  startIdx: 14
  endIdx: 15
  id: 13
}
connections {
  startIdx: 15
  endIdx: 16
  id: 14
}
connections {
  startIdx: 1
  endIdx: 23
  id: 15
}
connections {
  startIdx: 2
  endIdx: 22
  id: 16
}
connections {
  startIdx: 3
  endIdx: 21
  id: 17
}
connections {
  startIdx: 4
  endIdx: 20
  id: 18
}
connections {
  startIdx: 5
  endIdx: 19
  id: 19
}
connections {
  startIdx: 6
  endIdx: 18
  id: 20
}
connections {
  startIdx: 7
  endIdx: 17
  id: 21
}
connections {
  startIdx: 9
  endIdx: 18
  id: 22
}
connections {
  startIdx: 10
  endIdx: 19
  id: 23
}
connections {
  startIdx: 11
  endIdx: 20
  id: 24
}
connections {
  startIdx: 12
  endIdx: 21
  id: 25
}
connections {
  startIdx: 13
  endIdx: 22
  id: 26
}
connections {
  startIdx: 14
  endIdx: 23
  id: 27
}
connections {
  startIdx: 15
  endIdx: 24
  id: 28
}
